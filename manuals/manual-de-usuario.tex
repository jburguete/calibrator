\documentclass[a4paper]{report}

\usepackage[utf8]{inputenc}
\usepackage{listings}
\usepackage{pstricks}
\usepackage{multido}
\usepackage{amsfonts}
\usepackage{natbib}
\usepackage{graphicx}
\usepackage[spanish]{babel}

\newcommand{\EQ}[2]
{\begin{equation}#1\label{#2}\end{equation}}

\newcommand{\PICTURE}[5]
{
	\begin{figure}[ht!]
		\centering
		\begin{picture}(#1,#2)
			#3
		\end{picture}
		\caption{#4.\label{#5}}
	\end{figure}
}

\newcommand{\PSPICTURE}[7]
{
	\begin{figure}[ht!]
		\centering
		\pspicture(#1,#2)(#3,#4)
			#5
		\endpspicture
		\caption{#6.\label{#7}}
	\end{figure}
}

\newcommand{\TABLE}[5]
{
	\begin{table}[ht!]
		\centering
		\caption{#4.\label{#5}}
		#1
		\begin{tabular}{#2}
			#3
		\end{tabular}
	\end{table}
}

\newcommand{\FIGII}[4]
{
	\begin{figure}[ht!]
		\centering
		\begin{tabular}{c}
			\includegraphics{#1} \\ \includegraphics{#2}
		\end{tabular}
		\caption{#3.\label{#4}}
	\end{figure}
}

\newcommand{\FIGIV}[6]
{
	\begin{figure}[ht!]
		\centering
		\begin{tabular}{cc}
			\includegraphics{#1} & \includegraphics{#2} \\
			\includegraphics{#3} & \includegraphics{#4}
		\end{tabular}
		\caption{#5.\label{#6}}
	\end{figure}
}

\newcommand{\FIGVI}[8]
{
	\begin{figure}[ht!]
		\centering
		\begin{tabular}{cc}
			\includegraphics{#1} & \includegraphics{#2} \\
			\includegraphics{#3} & \includegraphics{#4} \\
			\includegraphics{#5} & \includegraphics{#6}
		\end{tabular}
		\caption{#7.\label{#8}}
	\end{figure}
}

\newcommand{\ABS}[1]{\left|#1\right|}
\newcommand{\PA}[1]{\left(#1\right)}

\bibliographystyle{abbrvnat}

\begin{document}

\title{Calibrator: un software libre para obtener parámetros empíricos
necesarios en modelos de simulación}

\author{Javier Burguete}

\maketitle

\chapter{Generando el fichero ejecutable a partir del código fuente}

El código fuente en Calibrator está escrito en lenguaje C. El programa ha sido
compilado y probado en los siguientes sistemas operativos:
\begin{itemize}
\item Debian kFreeBSD y Linux 8,
\item DragonFly BSD 4.2,
\item Dyson Illumos,
\item Fedora Linux 23,
\item FreeBSD 10,
\item NetBSD 7.0,
\item OpenBSD 5.8,
\item OpenSUSE Linux 13,
\item Ubuntu Linux 12, 14 and 15,
\item Windows 7\footnotemark[1],
\item and Windows 8.1\footnotemark[1].
\end{itemize}
Es probable que también puede compilarse y funcione en otros sistemas
operativos, otras distribuciones de software y otras versiones pero no ha sido
probado.
\footnotetext[1]{Windows 7 y Windows 8.1 son marcas registradas de Microsoft
Corporation.}

Para generar el fichero ejecutable a partir de código fuente, un compilador de C
(\citet{gcc} o \citet{clang}), los sistemas de configuración \citet{autoconf},
\citet{automake} y \citet{pkgconfig}, el programa de control de la creación de
ejecutables \citet{gnumake} and las siguienres librerías de software libre son
necesarias:
\begin{itemize}
\item\citet{libxml}: Librería requerida para leer el fichero principal de
entrada en formato XML.
\item\citet{gsl}: Librería científica usada para generar los números
pseudo-aleatorios usados por los algoritmos genético y de Monte-Carlo.
\item\citet{glib}: Librería requerida para analizar las plantillas de los
ficheros de entrada y para implementar algunos tipos de datos, funciones útiles
y rutinas usadas para paralelizar la carga computacional en los diferentes
procesadores de la máquina.
\item\citet{gtk}: Librería opcional usada para dibujar la interfaz gráfica
interactiva.
\item\citet{openmpi} o \citet{mpich}: Librerías opcionales. Cuando están
instaladas en el sistema una de ellas es usada para permitir la paralelización
del cálculo en múltiples computadoras.
\end{itemize}
Las indicaciones proporcionadas en \citet{install-unix} pueden seguirse para
instalar todas estas utilidades.

En OpenBSD 5.8, antes de generar el código, deben seleccionarse versiones
adecuadas de Autoconf y Automake haciendo en un terminal:
\begin{lstlisting}[language=bash,basicstyle=\scriptsize]
$ export AUTOCONF_VERSION=2.69 AUTOMAKE_VERSION=1.15
\end{lstlisting}

En sistemas Windows hay que instalar MSYS2
(http://sourceforge.net/projects/msys2) y las librerías y utilidades requeridas.
Para ello se pueden seguir las instrucciones detalladas en
https://github.com/jburguete/install-unix.

Una vez que todas las utilidades necesarias han sido instaladas, hay que
descargar el código de Genetic. Luego puede compilarse haciendo en un terminal:
\begin{lstlisting}[language=bash,basicstyle=\scriptsize]
$ git clone https://github.com/jburguete/genetic.git
$ cd genetic/0.6.1
$ ./build
\end{lstlisting}

El siguiente paso es descargar el código fuente de Calibrator, enlazarlo con el
de Genetic y compilar todo junto haciendo:
\begin{lstlisting}[language=bash,basicstyle=\scriptsize]
$ git clone https://github.com/jburguete/calibrator.git
$ cd calibrator/1.1.38
$ ln -s ../../genetic/0.6.1 genetic
$ ./build
\end{lstlisting}

Finalmente podemos construir los manuales en formato PDF haciendo:
\begin{lstlisting}[language=bash,basicstyle=\scriptsize]
$ make manuals
\end{lstlisting}

\chapter{Interfaz}

\section{Formato en línea de comandos}

\begin{itemize}

\item La línea de comandos en modo secuencial es (donde X es el número de tareas
a ejecutar paralelamente):
\begin{lstlisting}[language=bash,basicstyle=\scriptsize]
$ ./calibratorbin [-nthreads X] input_file.xml
\end{lstlisting}

\item La línea de comandos en modo paralelizado en diferentes computadoras con
MPI es (donde X es el número de tareas a ejecutar en cada nodo):
\begin{lstlisting}[language=bash,basicstyle=\scriptsize]
$ mpirun [MPI options] ./calibratorbin [-nthreads X] input_file.xml
\end{lstlisting}

\item La sintaxis del programa simulador ha de ser:
\begin{lstlisting}[language=bash,basicstyle=\scriptsize]
$ ./simulator_name input_file_1 [input_file_2] [...] output_file
\end{lstlisting}
Hay dos opciones para el fichero de salida. Puede comenzar con un número que
indique el valor de la función objetivo o puede ser un fichero de resultados que
tiene que ser evaluado por un programa externo (el evaluador) comparando con un
fichero de datos experimentales.

\item En caso de la última opción del punto anterior, la sintaxis del programa
para evaluar la función objetivo tiene que ser (donde el fichero de resultados
debe comenzar con el valor de la función objetivo):
\begin{lstlisting}[language=bash,basicstyle=\scriptsize]
$ ./evaluator_name simulated_file experimental_file results_file
\end{lstlisting}

\item En systemas de tipo UNIX, la aplicación interactiva puede abrirse haciendo
en un terminal:
\begin{lstlisting}[language=bash,basicstyle=\scriptsize]
$ ./calibrator
\end{lstlisting}

\end{itemize}

\section{Ficheros de entrada}

\subsection{Fichero de entrada principal}

Este fichero tiene que estar en formato XML con una estructura arbórea como la
representada en la figura~\ref{FigMainFile}.
\psset{xunit=0.4mm,yunit=0.4mm}
\PSPICTURE{0}{-115}{280}{15}
{
	\tiny
	\psframe(0,-5)(280,15)
	\psline(40,-5)(40,15)
	\rput(20,10){\bf calibrate}
	\rput(60,10){\bf simulator}
	\rput(100,10){\bf algorithm}
	\rput(140,10){evaluator}
	\rput(180,10){nsimulations}
	\rput(220,10){niterations}
	\rput(260,10){tolerance}
	\rput(55,0){nbest}
	\rput(85,0){npopulation}
	\rput(125,0){ngenerations}
	\rput(160,0){mutation}
	\rput(195,0){reproduction}
	\rput(235,0){adaptation}
	\rput(265,0){seed}
	\psline(20,-5)(20,-15)(40,-15)
	\psframe(40,-20)(280,-10)
	\psline(80,-20)(80,-10)
	\rput(60,-15){\bf experiment}
	\rput(95,-15){\bf name}
	\rput(125, -15){\bf template$_\mathbf{1}$}
	\rput(160,-15){template$_2$}
	\rput(195,-15){$\cdots$}
	\rput(230,-15){template$_n$}
	\rput(260,-15){weight}
	\psline(20,-15)(20,-25)
	\rput(140,-30){$\cdots$}
	\psline(20,-35)(20,-45)(40,-45)
	\psframe(40,-50)(280,-40)
	\psline(80,-50)(80,-40)
	\rput(60,-45){\bf experiment}
	\rput(95,-45){\bf name}
	\rput(125,-45){\bf template$_\mathbf{1}$}
	\rput(160,-45){template$_2$}
	\rput(195,-45){$\cdots$}
	\rput(230,-45){template$_n$}
	\rput(260,-45){weight}
	\psline(20,-45)(20,-65)(40,-65)
	\psframe(40,-75)(280,-55)
	\psline(80,-75)(80,-55)
	\rput(60,-60){\bf variable}
	\rput(100,-60){\bf name}
	\rput(140,-60){\bf minimum}
	\rput(180,-60){\bf maximum}
	\rput(230,-60){absolute\_minimum}
	\rput(110,-70){absolute\_maximum}
	\rput(160,-70){format}
	\rput(200,-70){nsweeps}
	\rput(240,-70){nbits}
	\psline(20,-65)(20,-80)
	\rput(140,-85){$\cdots$}
	\psline(20,-90)(20,-105)(40,-105)
	\psframe(40,-115)(280,-95)
	\psline(80,-115)(80,-95)
	\rput(60,-100){\bf variable}
	\rput(100,-100){\bf name}
	\rput(140,-100){\bf minimum}
	\rput(180,-100){\bf maximum}
	\rput(230,-100){absolute\_minimum}
	\rput(110,-110){absolute\_maximum}
	\rput(160,-110){format}
	\rput(200,-110){nsweeps}
	\rput(240,-110){nbits}
}{Estructura del fichero principal de entrada. Nodos y propiedades
imprescindibles están en negrita. No obstante, otras propiedades también pueden
ser necesarias en función del algoritmo de optimización seleccionado}
{FigMainFile}

El nodo XML principal tiene que comenzar con la etiqueta ``\emph{calibrate}''.
Las propiedades que se pueden definir son:
\begin{description}
	\item[simulator]: indica el programa simulador.
	\item[evaluator]: opcional. Especifica el programa de evaluación en caso de
		ser requerido.
	\item[algorithm]: fija el algoritmo de optimización. Actualmente tres
		métodos están disponibles:
	\begin{description}
		\item[sweep]: algoritmo de fuerza bruta de barrido. Requiere definir en
			cada variable:
		\begin{description}
			\item[nsweeps]: número de barridos para la variable en cada
				experimento.
		\end{description}
	\item[Monte-Carlo]: algoritmo de fuerza bruta de Monte-Carlo. Requiere
		definir en el nodo XML principal:
		\begin{description}
			\item[nsimulations]: número de simulaciones a ejecutar en cada
				iteración y en cada experimento.
		\end{description}
	\item[genetic]: algoritmo genético. Necesita definir los siguientes
		parámetros en el nodo XML principal:
		\begin{description}
			\item[npopulation]: número de individuos de la población.
			\item[ngenerations]: número de generaciones.
			\item[mutation]: ratio de mutación.
			\item[reproduction]: ratio de reproducción.
			\item[adaptation]: ratio de adaptación.
		\end{description}
	Además para cada variable:
		\begin{description}
			\item[nbits]: número de bits para codificar la variable.
		\end{description}
	\end{description}
\item[niterations]: número de iteraciones (valor por defecto: 1) para realizar
	el algoritmo iterativo.
\item[nbest]: número de mejores simulaciones con las que calcular el siguiente
	intervalo de convergencia en la siguiente iteración del algoritmo iterativo
	(valor por defecto: 1).
\item[tolerance]: parámetro de tolerancia para relajar el intervalo de
	convergencia del algoritmo iterativo (valor por defecto: 0)
\item[seed]: semilla del generador de números pseudo-aleatorios (valor por
	defecto 7007).
\end{description}

El primer tipo de nodos XML hijos tiene que comenzar con la etiqueta
``\emph{experiment}''. Especifica los datos experimentales. Contiene las
propiedades:
\begin{description}
	\item[name]: nombre del fichero de datos experimentales a calibrar.
	\item[templateX]: $X$-ésima plantilla del fichero de datos experimentales
		del programa de simulación.
	\item[weight]: peso (valor por defecto: 1) para aplicar en la función
		objetivo (véase (\ref{EqObjectiveFunction})).
\end{description}

El segundo tipo de nodos XML hijo tiene que comenzar con la etiqueta
\emph{variable}''. En estos nodos se especifican los datos de las variables que
se definen con las propiedades siguientes:
\begin{description}
	\item[name]: etiqueta de la variable. Para la variable $X$-ésima, se
		analizan todas las plantillas de entrada y se crean ficheros de entrada
		correspondientes para el programa simulador reemplazando todas las
		etiquetas con el formato @variableX@ por el contenido de esta propiedad.
\item[minimum, maximum]: rango de valores de las variables. El programa crea los
	ficheros de entrada de la simulación reemplazando todas las etiquetas
	@valueX@ de las plantillas de entrada por un valor en este rango para la
	vairable $X$-ésima, calculado por el algoritmo de optimización.
\item[absolute\_minimum, absolute\_maximum]: rango de valores permitido. En
	métodos iterativos, la tolerancia puede incrementar el rango inicial de
	valores en cada iteración. Estos valores son el rango permitido para las
	variables compatible con los límites del modelo.
\item[precision]: número de dígitos decimales de precisión. 0 se aplica a los
	números enteros.
\end{description}

\subsection{Ficheros de plantilla}

Hay que generar $N_{experiments}\times N_{inputs}$ ficheros de plantilla para
reproducir cada fichero de entrada asociado a cada uno de los experimentos
(véase la figura~\ref{FigStructure}). Todos estos ficheros de plantilla son
analizados sintáctimente por Calibrator reemplazándose las siguientes etiquetas
clave para generar los ficheros de entrada del programa simulador:
\begin{description}
\item[@variableX@]: se reemplaza por la etiqueta asociada al $X$-ésima parámetro
	empírico definido en el fichero principal de entrada.
\item[@valueX@]: se reemplaza por el valor asociado al $X$-ésima parámetro
	empírico calculado por el algoritmo de optimización usando los datos
	definidos en el fichero principal de entrada.
\end{description}

\section{Aplicación con interfaz gráfica de usuario interactiva}

Una forma alternativa de usar el programa consiste en usar la aplicación con
interfaz gráfica de usuario interactiva, llamada \emph{Calibrator}. En la
figure~\ref{FigWindow} se muestra una figura con la ventana principal de la
utilidad. Desde esta ventana podemos acceder a cada variable, coeficiente,
algoritmo y programa de simulación requerido.
\begin{figure}[ht!]
	\centering
	\includegraphics[width=\textwidth]{calibrator-es.eps}
	\caption{Ventana principal de la aplicación con interfaz gráfica de usuario
		interactiva de Calibrator.\label{FigWindow}}
\end{figure}

\section{Ficheros de salida}

\subsection{Fichero de resultados}

Calibrator genera un fichero denominado \emph{result} donde se guarda la mejor
combinación de variables y su correspondiente norma de error calculada.

\subsection{Fichero de variables}

El programa genera también un fichero llamado \emph{variables} donde se guarda
cada una de las combinaciones de variables probadas en la calibración. Los
valores de las variables se guardan en columnas siendo la última columna el
valor del error correspondiente.

\chapter{Organización de Calibrator}

Supongamos que buscamos un conjunto de $N_{parameters}$ parámetros empíricos 
requeridos por un modelo de simulación que sea el que mejor ajuste el conjunto
de $N_{experiments}$ datos experimentales y que el programa simulador requiere
además $N_{inputs}$ ficheros de entrada.
The structure followed by Calibrator is summarized in \emph{main input file},
where both $N_{experiments}$ and $N_{inputs}$ are specified. Furthermore, it
contains the extreme values of the empirical parameters and the chosen
optimization algorithm. Then, Calibrator reads the
$N_{experiments}\times N_{inputs}$ templates to build the simulator input files
replacing key labels by empirical parameter values created by the optimization
algorithm. There are two options: either the simulator compares directly the
simulation results with the \emph{experimental data file}, hence generating a
file with the value of the error, or an external program called \emph{evaluator}
is invoked to compare with the \emph{experimental data file} and to produce the
error value. In both cases this error value is saved in an
\emph{objective value file}. Then for each experiment, an objective value $o_i$
is obtained. The final value of the objective function associated with the
experiments is calculated by means of:
\EQ
{
	J=\sqrt{\frac{1}{N_{experiments}}
	\,\sum_{i=1}^{N_{experiments}}\ABS{w_i\,o_i}^2},
}{EqObjectiveFunction}
with $w_i$ the weight associated to the $i$-th experiment, specified in the
\emph{main input file}. Figure~\ref{FigStructure} is a sketch of the
structure.
\psset{xunit=0.4mm,yunit=0.4mm}
\PSPICTURE{-20}{-95}{280}{55}
{
	\tiny
	\rput(15,50){Main input file}
	\psframe(-20,45)(50,55)
	\psline{->}(50,50)(60,50)
	\rput(15,25){1st template file}
	\psframe(-20,20)(50,30)
	\psline{->}(50,25)(60,25)
	\psline[linestyle=dotted,dotsep=1pt]{->}(60,25)(90,25)
	\rput(15,15){$\cdots$}
	\rput(15,5){$n$-th template file}
	\psframe(-20,0)(50,10)
	\psline{->}(50,5)(60,5)
	\psline[linestyle=dotted,dotsep=1pt]{->}(60,5)(90,5)
	\rput(15,-35){$\cdots$}
	\rput(15,-75){$(N\times n)$-th template file}
	\psframe(-20,-70)(50,-80)
	\psline{->}(50,-75)(60,-75)
	\psline[linestyle=dotted,dotsep=1pt]{->}(60,-75)(90,-75)
	\rput(75,50){Calibrator}
	\psframe(60,-95)(90,55)
	\psline{->}(90,25)(100,25)
	\psline{->}(90,5)(100,5)
	\psline{->}(90,-55)(100,-55)
	\psline{->}(90,-75)(100,-75)
	\rput(120,5){$n$-th input file}
	\psframe(100,0)(140,10)
	\psline{->}(140,5)(150,5)
	\rput(120,15){$\cdots$}
	\rput(120,25){1st input file}
	\psframe(100,20)(140,30)
	\psline{->}(140,25)(145,25)(145,5)
	\rput(185,5){Simulator}
	\psframe(150,0)(220,10)
	\psline[linestyle=dashed,dash=2pt 1pt]{->}(185,10)(185,20)
	\psline[linestyle=dashed,dash=2pt 1pt]{->}(220,5)(230,7.5)
	\rput(185,25){Results file}
	\psframe[linestyle=dashed,dash=3pt 1pt](150,20)(220,30)
	\psline[linestyle=dashed,dash=2pt 1pt]{->}(220,25)(230,30)
	\rput(185,45){Experimental data file}
	\psframe(150,40)(220,50)
	\psline[linestyle=dashed,dash=2pt 1pt]{->}(220,45)(230,30)
	\psline[linestyle=dashed,dash=2pt 1pt]{->}(150,45)(145,45)(145,25)
	\rput(250,30){Evaluator}
	\psline[linestyle=dashed,dash=2pt 1pt]{->}(250,25)(250,15)
	\psframe[linestyle=dashed,dash=3pt 1pt](230,25)(270,35)
	\rput(250,10){Objective}
	\rput(250,5){value file}
	\psframe(230,0)(270,15)
	\psline{->}(270,7.5)(280,7.5)(280,-90)(90,-90)
	\rput(15,-90){Objective function value}
	\psframe(-20,-95)(50,-85)
	\psline{->}(60,-90)(50,-90)
	\psline[linestyle=dotted,dotsep=1pt]{->}(90,-90)(60,-90)
	\rput(120,50){1st experiment}
	\psframe[linestyle=dotted](95,-5)(275,55)
	\rput(185,-15){$\cdots$}
	\rput(120,-75){$n$-th input file}
	\psframe(100,-80)(140,-70)
	\psline{->}(140,-75)(150,-75)
	\rput(120,-65){$\cdots$}
	\rput(120,-55){1st input file}
	\psframe(100,-60)(140,-50)
	\psline{->}(140,-55)(145,-55)(145,-75)
	\rput(185,-75){Simulator}
	\psframe(150,-80)(220,-70)
	\psline[linestyle=dashed,dash=2pt 1pt]{->}(185,-70)(185,-60)
	\psline[linestyle=dashed,dash=2pt 1pt]{->}(220,-75)(230,-72.5)
	\rput(185,-55){Results file}
	\psframe[linestyle=dashed,dash=3pt 1pt](150,-60)(220,-50)
	\psline[linestyle=dashed,dash=2pt 1pt]{->}(220,-55)(230,-50)
	\rput(185,-35){Experimental data file}
	\psframe(150,-40)(220,-30)
	\psline[linestyle=dashed,dash=2pt 1pt]{->}(220,-35)(230,-50)
	\psline[linestyle=dashed,dash=2pt 1pt]{->}(150,-35)(145,-35)(145,-55)
	\rput(250,-50){Evaluator}
	\psline[linestyle=dashed,dash=2pt 1pt]{->}(250,-55)(250,-65)
	\psframe[linestyle=dashed,dash=3pt 1pt](230,-55)(270,-45)
	\rput(250,-70){Objective}
	\rput(250,-75){value file}
	\psframe(230,-80)(270,-65)
	\psline(270,-72.5)(280,-72.5)
	\rput(120,-30){$N$-th experiment}
	\psframe[linestyle=dotted](95,-85)(275,-25)
}{Flowchart of the interactions among Calibrator, the input files and the
simulation and evaluation programs to produce an objective function value for
each empirical parameters combination generated by the optimization algorithm}
{FigStructure}

The whole process is repeated for each combination of empirical parameters generated by the optimization algorithm. Furthermore, Calibrator automatically parallelizes the simulations using all the available computing resources.

The required format for the \emph{main input file} and the \emph{template files} are described in next section.

\chapter{Optimization methods}

The optimization methods implemented in Calibrator are next presented. The following notation will be used:
\begin{description}
	\item[$N_{simulations}$]: number of simulations made for each iteration.
	\item[$N_{iterations}$]: number of iterations on iterative methods.
	\item[$N_{total}$]: total number of simulations.
\end{description}
In iterative methods $N_{total}=N_{simulations}\times N_{iterations}$.
In pure brute force methods
$N_{iterations}=1\;\Rightarrow\;N_{total}=N_{simulations}$.

\section{Sweep brute force method}

The sweep brute force method finds the optimal set of parameters within a solution region by dividing it into regular subdomains. To find the optimal solution, the domain interval $x_i \in \PA{x_{i,min},\,x_{i,max}}$ is first defined for each variable $x_i$. Then, a regular partition in  $N_{x,i}$ subintervals is made. Taking into account this division of the solution space, the number of required simulations is:
\EQ{N_{simulations}=N_{x,1}\times N_{x,2}\times\cdots,}
{EqNSweeps}
where $N_{x,i}$ is the number of sweeps in the variable $x_i$.

In figure~\ref{FigSweep} the $(x,y)$ domain is defined by the intervals $x\in\PA{x_{min},\,x_{max}}$ and $y \in \PA{y_{min},\,y_{max}}$. Both $x$ and $y$ intervals are divided into 5 regions with $N_{x}=N_{y}=5$. The optimal will be found within the region by evaluating the error of each $\PA{x_i,\,y_i}$ set of parameters hence requiring 25 evaluations. Note that the computational cost increases strongly as the number of variables grow.

\PICTURE{210}{200}
{
	\put(20,10){\vector(0,1){180}}
	\put(20,10){\vector(1,0){180}}
	\put(10,190){$y$}
	\put(200,0){$x$}
	\multiput(50,40)(30,0){5}{\qbezier[40](0,0)(0,60)(0,120)}
	\multiput(50,40)(0,30){5}{\qbezier[40](0,0)(60,0)(120,0)}
	\multiput(50,40)(30,0){5}{\multiput(0,0)(0,30){5}{\circle*{2}}}
	\qbezier[10](50,10)(50,25)(50,40)
	\put(40,0){$x_{\min}$}
	\qbezier[10](170,10)(170,25)(170,40)
	\put(160,0){$x_{\max}$}
	\qbezier[10](20,40)(35,40)(50,40)
	\put(0,37){$y_{\min}$}
	\qbezier[10](20,160)(35,160)(50,160)
	\put(0,157){$y_{\max}$}
}{Diagram showing an example of application of the sweep brute force method
with two variables for $N_x=N_y=5$}{FigSweep}

Brute force algorithms present low convergence rates but they are strongly
parallelizable because every simulation is completely independent. If the
computer, or the computers cluster, can execute $N_{tasks}$ parallel tasks
every task do $N_{total}/N_{tasks}$ simulations, obviously taking into account
rounding effects (every task has to perform a natural number of simulations).
In figure~\ref{FigBruteForceParallelization} a flowchart of this parallelization
scheme is represented. Being independent each task, a distribution on different
execution threads may be performed exploding the full parallel capabilities of
the machine where Calibrator is run.

\psset{xunit=0.5mm,yunit=0.5mm}
\PSPICTURE{-90}{-55}{90}{-15}
{
	\tiny
	\rput(0,-15){Generation of $N_{total}$ empirical parameters sets}
	\psframe(-55,-20)(55,-10)
	\psline{->}(0,-20)(-50,-25)
	\psline{->}(0,-20)(0,-25)
	\psline{->}(0,-20)(55,-25)
	\rput(-55,-30){1st task:}
	\rput(-55,-35){$N_{total}/N_{tasks}$ simulations}
	\psframe(-90,-25)(-20,-40)
	\rput(0,-32.5){$\cdots$}
	\rput(55,-30){$N_{tasks}$-th task:}
	\rput(55,-35){$N_{total}/N_{tasks}$ simulations}
	\psframe(20,-25)(90,-40)
	\psline{->}(-55,-40)(0,-45)
	\psline{->}(0,-40)(0,-45)
	\psline{->}(55,-40)(0,-45)
	\rput(0,-50){Getting optimal empirical parameters set}
	\psframe(-50,-45)(50,-55)
}{Flowchart of the parallelization scheme in Calibrator for brute force methods
(sweep and Monte-Carlo)}{FigBruteForceParallelization}

\section{Monte-Carlo method}

Monte-Carlo based methods run simulations using aleatory values of the
variables assuming  uniform probability within the extreme values range.
Figure~\ref{FigMonteCarlo} shows the structure of an example using two
variables.

\PICTURE{210}{200}
{
	\put(20,10){\vector(0,1){180}}
	\put(20,10){\vector(1,0){180}}
	\put(10,190){$y$}
	\put(200,0){$x$}
	\put(69,159){\circle*{2}}
	\put(163,73){\circle*{2}}
	\put(108,67){\circle*{2}}
	\put(139,154){\circle*{2}}
	\put(138,104){\circle*{2}}
	\put(129,131){\circle*{2}}
	\put(146,77){\circle*{2}}
	\put(70,102){\circle*{2}}
	\put(97,97){\circle*{2}}
	\put(75,66){\circle*{2}}
	\put(90,43){\circle*{2}}
	\put(163,63){\circle*{2}}
	\put(157,109){\circle*{2}}
	\put(109,119){\circle*{2}}
	\put(71,107){\circle*{2}}
	\put(64,75){\circle*{2}}
	\put(127,47){\circle*{2}}
	\put(126,127){\circle*{2}}
	\put(61,125){\circle*{2}}
	\put(62,123){\circle*{2}}
	\put(110,55){\circle*{2}}
	\put(84,64){\circle*{2}}
	\put(65,49){\circle*{2}}
	\put(59,105){\circle*{2}}
	\put(156,75){\circle*{2}}	
	\qbezier[50](50,10)(50,85)(50,160)
	\put(40,0){$x_{\min}$}
	\qbezier[50](170,10)(170,85)(170,160)
	\put(160,0){$x_{\max}$}
	\qbezier[50](20,40)(95,40)(170,40)
	\put(0,37){$y_{\min}$}
	\qbezier[50](20,160)(95,160)(170,160)
	\put(0,157){$y_{\max}$}
}{Diagram illustrating a Monte-Carlo brute force method with two variables and
$N_{simulations}=25$}{FigMonteCarlo}

Monte-Carlo method is also easily parallelizable following a strategy as the
flowchart represented in the figure~\ref{FigBruteForceParallelization}.

\section{Iterative algorithm applied to brute force methods}

Calibrator allows to iterate both sweep or Monte-Carlo brute force methods in
order to seek convergence. In this case, the best results from the previous
iteration are used to force new intervals in the variables for the following
iteration. Then for $N_{best}^j$, the subset of the best simulation results in
the $j$-th iteration, the following quantities are defined:
\begin{description}
\item[$\displaystyle x_{\max}^b=\max_{i\in N_{best}}x_i^j$]: Maximum value of
	variable $x$ in the subset of the best simulation results from the $j$-th
	iteration.
\item[$\displaystyle x_{\min}^b=\max_{i\in N_{best}}x_i^j$]: Minimum value of
	variable $x$ in the subset of the best simulation results from the $j$-th
	iteration.
\end{description}
A new interval in the variable $x$ is defined to build the optimization values in the next $(j+1)$ iteration so that:
\EQ{x_i^{j+1}\in\left[x_{\min}^{j+1},\;x_{\max}^{j+1}\right],}
{EqIterationInterval}
with:
\[
	x_{\max}^{j+1}=\frac{x_{\max}^b+x_{\min}^b
		+\left(x_{\max}^b-x_{\min}^b\right)(1+tolerance)}{2},
\]
\[
	x_{\min}^{j+1}=\frac{x_{\max}^b+x_{\min}^b
		-\left(x_{\max}^b-x_{\min}^b\right)(1+tolerance)}{2},
\]
being $tolerance$ a factor increasing the size of the variable intervals to
simulate the next iteration.
Figure~\ref{FigIterative} contains a sketch of the procedure used by the the iterative algorithm to modify the variables intervals in order to enforce convergence. 

\PICTURE{210}{400}
{
	\small
	\multiput(0,0)(0,200){2}
	{
		\put(20,10){\vector(0,1){180}}
		\put(20,10){\vector(1,0){180}}
		\put(10,190){$y$}
		\put(200,0){$x$}
	}
	\put(90,380){1st iteration}
	\put(50,370){*: best results}
	\put(69,359){\circle*{2}}
	\put(163,273){\circle*{2}}
	\put(108,267){*}
	\put(139,354){\circle*{2}}
	\put(138,304){*}
	\put(129,331){\circle*{2}}
	\put(146,277){\circle*{2}}
	\put(70,302){\circle*{2}}
	\put(97,297){*}
	\put(75,266){\circle*{2}}
	\put(90,243){\circle*{2}}
	\put(163,263){\circle*{2}}
	\put(157,309){\circle*{2}}
	\put(109,319){*}
	\put(71,307){\circle*{2}}
	\put(64,275){\circle*{2}}
	\put(127,247){\circle*{2}}
	\put(126,327){\circle*{2}}
	\put(61,325){\circle*{2}}
	\put(62,323){\circle*{2}}
	\put(110,255){\circle*{2}}
	\put(84,264){\circle*{2}}
	\put(65,249){\circle*{2}}
	\put(59,305){\circle*{2}}
	\put(156,275){\circle*{2}}	
	\qbezier[50](50,210)(50,285)(50,360)
	\put(40,200){$x_{\min}^1$}
	\qbezier[50](170,210)(170,285)(170,360)
	\put(160,200){$x_{\max}^1$}
	\qbezier[50](20,240)(95,240)(170,240)
	\put(0,237){$y_{\min}^1$}
	\qbezier[50](20,360)(95,360)(170,360)
	\put(0,357){$y_{\max}^1$}
	\qbezier[21](99,272)(119.5,272)(140,272)
	\qbezier[21](99,324)(119.5,324)(140,324)
	\qbezier[26](99,272)(99,298)(99,324)
	\qbezier[26](140,272)(140,298)(140,324)
	\put(99,267){\vector(1,0){41}}
	\put(140,267){\vector(-1,0){41}}
	\put(95,255){$x_{\max}^b-x_{\min}^b$}
	\put(94.9,215){\vector(1,0){49.2}}
	\put(144.1,215){\vector(-1,0){49.2}}
	\put(95,220){$x_{\max}^2-x_{\min}^2$}
	\qbezier[20](99,272)(96.95,241)(94.9,210)
	\qbezier[20](140,272)(142.05,241)(144.1,210)
	\qbezier[26](99,272)(69.5,269.4)(20,266.8)
	\qbezier[26](99,324)(69.5,326.6)(20,329.2)
	\put(80,180){2nd iteration}
	\put(102,123){\circle*{2}}
	\put(141,83){\circle*{2}}
	\put(118,80){\circle*{2}}
	\put(131,121){\circle*{2}}
	\put(131,97){\circle*{2}}
	\put(127,110){\circle*{2}}
	\put(134,84){\circle*{2}}
	\put(103,96){\circle*{2}}
	\put(114,94){\circle*{2}}
	\put(105,79){\circle*{2}}
	\put(111,68){\circle*{2}}
	\put(141,78){\circle*{2}}
	\put(139,100){\circle*{2}}
	\put(119,104){\circle*{2}}
	\put(103,98){\circle*{2}}
	\put(100,83){\circle*{2}}
	\put(126,70){\circle*{2}}
	\put(126,108){\circle*{2}}
	\put(99,107){\circle*{2}}
	\put(100,106){\circle*{2}}
	\put(119,74){\circle*{2}}
	\put(109,78){\circle*{2}}
	\put(101,71){\circle*{2}}
	\put(99,98){\circle*{2}}
	\put(138,83){\circle*{2}}
	\qbezier[40](94.9,10)(94.9,69.6)(94.9,129.2)
	\put(84.9,0){$x_{\min}^2$}
	\qbezier[40](144.1,10)(144.1,69.6)(144.1,129.2)
	\put(134.1,0){$x_{\max}^2$}
	\qbezier[41](20,129.2)(82.05,129.2)(144.1,129.2)
	\put(0,126.2){$y_{\max}^2$}
	\qbezier[41](20,66.8)(82.05,66.8)(144.1,66.8)
	\put(0,63.8){$y_{\min}^2$}
}{Diagram representing an example of the iterative algorithm applied to a
Monte-Carlo brute force method with two variables for $N_{simulations}= 25$,
$N_{best}=4$ and two iterations}{FigIterative}

The iterative algorithm can be also easily parallelized. However, this method is
less parallelizable than pure brute force methods because the parallelization
has to be performed for each iteration (see a flowchart in the
figure~\ref{FigIterativeParallelization}).

\psset{xunit=0.5mm,yunit=0.5mm}
\PSPICTURE{-100}{-130}{100}{-15}
{
	\tiny
	\rput(0,-15){1st iteration:}
	\rput(0,-20){Generation of $N_{simulations}$ empirical parameters sets}
	\psframe(-60,-25)(60,-10)
	\psline{->}(0,-25)(-60,-30)
	\psline{->}(0,-25)(0,-30)
	\psline{->}(0,-25)(60,-30)
	\rput(-60,-35){1st task:}
	\rput(-60,-40){$N_{simulations}/N_{tasks}$ simulations}
	\psframe(-100,-30)(-20,-45)
	\rput(0,-37.5){$\cdots$}
	\rput(60,-35){$N_{tasks}$-th task:}
	\rput(60,-40){$N_{simulations}/N_{tasks}$ simulations}
	\psframe(20,-30)(100,-45)
	\psline{->}(-60,-45)(0,-50)
	\psline{->}(0,-45)(0,-50)
	\psline{->}(60,-45)(0,-50)
	\rput(0,-55){Getting $N_{best}$ empirical parameters sets}
	\psframe(-55,-50)(55,-60)
	\psline{->}(0,-60)(0,-65)
	\rput(0,-70){$\cdots$}
	\psline{->}(0,-75)(0,-80)
	\rput(0,-85){$N_{iterations}$-th iteration:}
	\rput(0,-90){Generation of $N_{simulations}$ empirical parameters sets}
	\psframe(-60,-95)(60,-80)
	\psline{->}(0,-95)(-60,-100)
	\psline{->}(0,-95)(0,-100)
	\psline{->}(0,-95)(60,-100)
	\rput(-60,-105){1st task:}
	\rput(-60,-110){$N_{simulations}/N_{tasks}$ simulations}
	\psframe(-100,-100)(-20,-115)
	\rput(0,-107.5){$\cdots$}
	\rput(60,-105){$N_{tasks}$-th task:}
	\rput(60,-110){$N_{simulations}/N_{tasks}$ simulations}
	\psframe(20,-100)(100,-115)
	\psline{->}(-60,-115)(0,-120)
	\psline{->}(0,-115)(0,-120)
	\psline{->}(60,-115)(0,-120)
	\rput(0,-125){Getting optimal empirical parameters set}
	\psframe(-55,-120)(55,-130)
}{Flowchart of the parallelization scheme in Calibrator for the iterative
method}{FigIterativeParallelization}

\section{Genetic method}

Calibrator also offers the use of a genetic method Genetic \cite{genetic} with its default algorithms.
It is inspired on the ideas in \citet{gaul}, but it has been fully reprogrammed involving more modern external libraries.
The code in Genetic is also open source under BSD license. Figure~\ref{FigGeneticFlow} shows the flowchart of the genetic method implemented in Genetic.

\psset{xunit=0.5mm,yunit=0.5mm}
\PSPICTURE{-120}{-185}{120}{20}
{
	\tiny
	\rput(0,15){Generation of $N_{population}$}
	\rput(0,10){random genomes}
	\psframe(-35,5)(35,20)
	\psline{->}(0,5)(0,0)
	\rput(0,-5){$generation=1$}
	\psframe(-25,-10)(25,0)
	\psline{->}(0,-10)(0,-15)
	\rput(0,-20){Simulation of the $N_{population}$}
	\rput(0,-25){entities}
	\psframe(-40,-30)(40,-15)
	\psline{->}(0,-30)(0,-35)
	\rput(0,-40){Sorting the $N_{population}$}
	\rput(0,-45){entities by objective function value}
	\psframe(-45,-50)(45,-35)
	\psline{->}(0,-50)(0,-55)
	\rput(0,-60){Eliminating the worst}
	\rput(0,-65){$N_{mutation}+N_{reproduction}+N_{adaptation}$ entities}
	\psframe(-65,-70)(65,-55)
	\psline{->}(0,-70)(-80,-75)
	\rput(-80,-80){Generation of $N_{mutation}$}
	\rput(-80,-85){new entities by mutation}
	\psframe(-115,-90)(-45,-75)
	\psline{->}(-80,-90)(-80,-95)
	\rput(-80,-100){Simulation of the $N_{mutation}$}
	\rput(-80,-105){new mutated entities}
	\psframe(-115,-110)(-45,-95)
	\psline{->}(0,-70)(0,-75)
	\rput(0,-80){Generation of $N_{reproduction}$}
	\rput(0,-85){new entities by reproduction}
	\psframe(-40,-90)(40,-75)
	\psline{->}(0,-90)(0,-95)
	\rput(0,-100){Simulation of the $N_{reproduction}$}
	\rput(0,-105){new reproduced entities}
	\psframe(-40,-110)(40,-95)
	\psline{->}(0,-70)(82.5,-75)
	\rput(82.5,-80){Generation of $N_{adaptation}$}
	\rput(82.5,-85){new entities by adaptation}
	\psframe(120,-90)(45,-75)
	\psline{->}(82.5,-90)(82.5,-95)
	\rput(82.5,-100){Simulation of the $N_{adaptation}$}
	\rput(82.5,-105){new adapted entities}
	\psframe(120,-110)(45,-95)
	\psline{->}(-80,-110)(0,-115)
	\psline{->}(0,-110)(0,-115)
	\psline{->}(82.5,-110)(0,-115)
	\rput(0,-120){Sorting the old $N_{survival}$ entities and the new}
	\rput(0,-125){$N_{mutation}+N_{reproduction}+N_{adaptation}$ entities}
	\rput(0,-130){by objective function values}
	\psframe(-65,-115)(65,-135)
	\psline{->}(0,-135)(0,-140)
	\rput(0,-145){Increase $+1$ $generation$}
	\psframe(-30,-140)(30,-150)
	\psline{->}(0,-150)(0,-155)
	\rput(0,-162.5){$generation<N_{generations}$?}
	\pspolygon(-50,-162.5)(0,-170)(50,-162.5)(0,-155)
	\psline{->}(-50,-162.5)(-120,-162.5)(-120,-62.5)(-65,-62.5)
	\rput(-60,-160){Yes}
	\rput(-5,-172.5){No}
	\psline{->}(0,-170)(0,-175)
	\rput(0,-180){Select the best entity}
	\psframe(-30,-185)(30,-175)
}{Flow diagram of the genetic method implemented in Genetic}{FigGeneticFlow}

\subsection{The genome}

The variables to calibrate/optimize are coded in Genetic using a bit chain: the
genome. The larger the number of bits assigned to a variable the higher the resolution.
The number of bits assigned to each variable, and therefore the genome size, is fixed and the same for all the 
simulations. Figure~\ref{FigGenome} shows an example for the coding of three variables. The value assigned to a variable $x$ is determined by the allowed extreme values $x_{\min}$ and $x_{\max}$, the binary number assigned in the genome to variable $I_x$ and by the number of bits assigned to variable $N_x$ according to
the following formula:
\EQ{x=x_{\min}+\frac{I_x}{2^{N_x}}\,\left(x_{\max}-x_{\min}\right).}{EqGenome}

\psset{unit=1mm}
\PSPICTURE{0}{0}{80}{30}
{
	\scriptsize
	\rput(40,27){Genome}
	\rput(15,23){Variable 1}
	\pspolygon(0,15)(30,15)(30,20)(0,20)
	\rput(40,23){Variable 2}
	\pspolygon(30,15)(50,15)(50,20)(30,20)
	\rput(65,23){Variable 3}
	\pspolygon(50,15)(80,15)(80,20)(50,20)
	\psline{->}(10,12)(0,12)
	\rput(5,9){Less}
	\rput(5,6){significant}
	\rput(5,3){bit}
	\psline{->}(20,12)(30,12)
	\rput(25,9){More}
	\rput(25,6){significant}
	\rput(25,3){bit}
	\rput(2,17.5){1}
	\rput(4,17.5){0}
	\rput(6,17.5){0}
	\rput(8,17.5){1}
	\rput(10,17.5){0}
	\rput(12,17.5){0}
	\rput(14,17.5){1}
	\rput(16,17.5){1}
	\rput(18,17.5){1}
	\rput(20,17.5){1}
	\rput(22,17.5){1}
	\rput(24,17.5){1}
	\rput(26,17.5){0}
	\rput(28,17.5){1}
	\rput(32,17.5){1}
	\rput(34,17.5){0}
	\rput(36,17.5){0}
	\rput(38,17.5){0}
	\rput(40,17.5){0}
	\rput(42,17.5){0}
	\rput(44,17.5){0}
	\rput(46,17.5){0}
	\rput(48,17.5){0}
	\rput(52,17.5){1}
	\rput(54,17.5){1}
	\rput(56,17.5){1}
	\rput(58,17.5){1}
	\rput(60,17.5){0}
	\rput(62,17.5){1}
	\rput(64,17.5){0}
	\rput(66,17.5){0}
	\rput(68,17.5){0}
	\rput(70,17.5){0}
	\rput(72,17.5){1}
	\rput(74,17.5){1}
	\rput(76,17.5){1}
	\rput(78,17.5){1}
}{Example coding three variables to optimize into a
genome. The first and third variables have been coded with 14 bits, and the second
variable has been coded with 9 bits}{FigGenome}

\subsection{Survival of the best individuals}

In a population with $N_{population}$ individuals, in the first generation all the cases are simulated. The input variables are
taken from the genome of each individual. Next, in every generation, $N_{population}\times R_{mutation}$ individuals are generated by mutation, $N_{population}\times R_{reproduction}$ individuals are generated by reproduction and $N_{population}\times R_{adaptation}$ individuals are generated by adaptation, obviously
taking into account rounding. On second and further generations only simulations
associated to this new individuals ($N_{new}$) have to be run:
\EQ
{
	N_{new}=N_{population}
	\times\left(R_{mutation}+R_{reproduction}+R_{adaptation}\right).
}{EqNew}
Then, total number of simulations performed by the genetic algorithm is:
\EQ
{
	N_{total}=N_{population}+\left(N_{generations}-1\right)\times N_{new},
}{EqGeneticNumber}
with $N_{generations}$ the number of generations of new entities.
The individuals of the former population that obtained lower values in the evaluation function are replaced so that the best $N_{survival}$ individuals survive:
\EQ
{
	N_{survival}=N_{population}-N_{new}.
}{EqSurvival}
Furthermore, the ancestors to generate new individuals are chosen among the surviving population. Obviously, to have survival population, the following condition has to be enforced:
\EQ{R_{mutation}+R_{reproduction}+R_{adaptation}<1}{EqSurvivalCondition}
Calibrator uses a default aleatory criterion in Genetic, with a probability linearly decreasing with the ordinal in the ordered set of surviving individuals (see figure~\ref{FigSelection}).

\PICTURE{250}{110}
{
	\scriptsize
	\put(10,20){\vector(0,1){80}}
	\put(10,20){\vector(1,0){235}}
	\put(0,102){Probability to be selected as parent}
	\put(30,0){Survival population sorted by objective function values}
	\multiput(20,20)(10,0){2}{\line(0,1){66}}
	\put(20,86){\line(1,0){10}}
	\put(19,10){1st}
	\multiput(40,20)(10,0){2}{\line(0,1){60}}
	\put(40,80){\line(1,0){10}}
	\put(39,10){2nd}
	\multiput(60,20)(10,0){2}{\line(0,1){54}}
	\put(60,74){\line(1,0){10}}
	\put(59,10){3rd}
	\multiput(80,20)(10,0){2}{\line(0,1){48}}
	\put(80,68){\line(1,0){10}}
	\put(79,10){4th}
	\multiput(100,20)(10,0){2}{\line(0,1){42}}
	\put(100,62){\line(1,0){10}}
	\put(140,10){...}
	\multiput(120,20)(10,0){2}{\line(0,1){36}}
	\put(120,56){\line(1,0){10}}
	\multiput(140,20)(10,0){2}{\line(0,1){30}}
	\put(140,50){\line(1,0){10}}
	\multiput(160,20)(10,0){2}{\line(0,1){24}}
	\put(160,44){\line(1,0){10}}
	\multiput(180,20)(10,0){2}{\line(0,1){18}}
	\put(180,38){\line(1,0){10}}
	\multiput(200,20)(10,0){2}{\line(0,1){12}}
	\put(200,32){\line(1,0){10}}
	\multiput(220,20)(10,0){2}{\line(0,1){6}}
	\put(220,26){\line(1,0){10}}
	\put(205,10){$N_{survival}$-th}
	\qbezier[54](10,90.5)(127.5,50.25)(245,20)
}{Probability of a survival entity to be selected as parent
of the new entities generated by mutation, reproduction or adaptation
algorithms}{FigSelection}

\subsection{Mutation algorithm}

In the mutation algorithm an identical copy of the parent genome is made except for a bit, randomly chosen with uniform probability, which is inverted. Figure~\ref{FigMutation} shows an example of the procedure.
\psset{unit=1mm}
\PSPICTURE{0}{0}{80}{20}
{
	\scriptsize
	\rput(10,17.5){Parent}
	\pspolygon(20,15)(80,15)(80,20)(20,20)
	\rput(22,17.5){1}
	\rput(24,17.5){1}
	\rput(26,17.5){0}
	\rput(28,17.5){1}
	\rput(30,17.5){1}
	\rput(32,17.5){1}
	\rput(34,17.5){0}
	\rput(36,17.5){0}
	\rput(38,17.5){0}
	\rput(40,17.5){0}
	\rput(42,17.5){0}
	\rput(44,17.5){0}
	\rput(46,17.5){0}
	\rput(48,17.5){0}
	\rput(50,17.5){1}
	\rput(52,17.5){1}
	\rput(54,17.5){1}
	\rput(56,17.5){1}
	\rput(58,17.5){1}
	\rput(60,17.5){0}
	\rput(62,17.5){1}
	\rput(64,17.5){0}
	\rput(66,17.5){0}
	\rput(68,17.5){0}
	\rput(70,17.5){0}
	\rput(72,17.5){1}
	\rput(74,17.5){1}
	\rput(76,17.5){1}
	\rput(78,17.5){1}
	\rput(10,2.5){Son}
	\pspolygon(20,0)(80,0)(80,5)(20,5)
	\rput(22,2.5){1}
	\rput(24,2.5){1}
	\rput(26,2.5){0}
	\rput(28,2.5){1}
	\rput(30,2.5){1}
	\rput(32,2.5){1}
	\rput(34,2.5){0}
	\rput(36,2.5){1}
	\rput(38,2.5){0}
	\rput(40,2.5){0}
	\rput(42,2.5){0}
	\rput(44,2.5){0}
	\rput(46,2.5){0}
	\rput(48,2.5){0}
	\rput(50,2.5){1}
	\rput(52,2.5){1}
	\rput(54,2.5){1}
	\rput(56,2.5){1}
	\rput(58,2.5){1}
	\rput(60,2.5){0}
	\rput(62,2.5){1}
	\rput(64,2.5){0}
	\rput(66,2.5){0}
	\rput(68,2.5){0}
	\rput(70,2.5){0}
	\rput(72,2.5){1}
	\rput(74,2.5){1}
	\rput(76,2.5){1}
	\rput(78,2.5){1}
	\psline{->}(50,15)(50,5)
	\rput(60,10){Mutation}
	\pspolygon(35,15)(37,15)(37,20)(35,20)
	\pspolygon(35,5)(37,5)(37,0)(35,0)
	\psline{->}(32,10)(36,10)(36,15)
	\psline{->}(32,10)(36,10)(36,5)
	\rput(16,10){Inversion of a random bit}
}{Diagram showing an example of the generation of a new entity by mutation}
{FigMutation}

\subsection{Reproduction algorithm}

The default algorithm in Genetic selects two different parents with one of the least errors after the 
complete simulation of one generation. 
A new individual is then generated by sharing the common bits of both parents and a random choice in the others.
The new child has the same number of bits as the parents and different genome. Figure~\ref{FigReproduction} shows a sketch
of the algorithm.

\psset{unit=1mm}
\PSPICTURE{0}{0}{80}{20}
{
	\scriptsize
	\multido{\rb=0+7.5,\rt=5+7.5}{3}
	{
		\psframe[linecolor=gray,fillcolor=gray,fillstyle=solid](20,\rb)(23,\rt)
		\psframe[linecolor=gray,fillcolor=gray,fillstyle=solid](25,\rb)(29,\rt)
		\psframe[linecolor=gray,fillcolor=gray,fillstyle=solid](45,\rb)(47,\rt)
		\psframe[linecolor=gray,fillcolor=gray,fillstyle=solid](49,\rb)(51,\rt)
		\psframe[linecolor=gray,fillcolor=gray,fillstyle=solid](59,\rb)(61,\rt)
		\psframe[linecolor=gray,fillcolor=gray,fillstyle=solid](63,\rb)(67,\rt)
		\psframe[linecolor=gray,fillcolor=gray,fillstyle=solid](71,\rb)(75,\rt)
	}
	\rput(10,17.5){1st parent}
	\psframe(20,15)(80,20)
	\rput(22,17.5){1}
	\rput(24,17.5){1}
	\rput(26,17.5){0}
	\rput(28,17.5){1}
	\rput(30,17.5){1}
	\rput(32,17.5){1}
	\rput(34,17.5){0}
	\rput(36,17.5){0}
	\rput(38,17.5){0}
	\rput(40,17.5){0}
	\rput(42,17.5){0}
	\rput(44,17.5){0}
	\rput(46,17.5){0}
	\rput(48,17.5){0}
	\rput(50,17.5){1}
	\rput(52,17.5){1}
	\rput(54,17.5){1}
	\rput(56,17.5){1}
	\rput(58,17.5){1}
	\rput(60,17.5){0}
	\rput(62,17.5){1}
	\rput(64,17.5){0}
	\rput(66,17.5){0}
	\rput(68,17.5){0}
	\rput(70,17.5){0}
	\rput(72,17.5){1}
	\rput(74,17.5){1}
	\rput(76,17.5){1}
	\rput(78,17.5){1}
	\rput(10,2.5){2nd parent}
	\psframe(20,0)(80,5)
	\rput(22,2.5){1}
	\rput(24,2.5){0}
	\rput(26,2.5){0}
	\rput(28,2.5){1}
	\rput(30,2.5){0}
	\rput(32,2.5){0}
	\rput(34,2.5){1}
	\rput(36,2.5){1}
	\rput(38,2.5){1}
	\rput(40,2.5){1}
	\rput(42,2.5){1}
	\rput(44,2.5){1}
	\rput(46,2.5){0}
	\rput(48,2.5){1}
	\rput(50,2.5){1}
	\rput(52,2.5){0}
	\rput(54,2.5){0}
	\rput(56,2.5){0}
	\rput(58,2.5){0}
	\rput(60,2.5){0}
	\rput(62,2.5){0}
	\rput(64,2.5){0}
	\rput(66,2.5){0}
	\rput(68,2.5){1}
	\rput(70,2.5){1}
	\rput(72,2.5){1}
	\rput(74,2.5){1}
	\rput(76,2.5){0}
	\rput(78,2.5){0}
	\rput(10,10){Son}
	\psframe(20,7.5)(80,12.5)
	\rput(22,10){1}
	\rput(24,10){0}
	\rput(26,10){0}
	\rput(28,10){1}
	\rput(30,10){0}
	\rput(32,10){0}
	\rput(34,10){0}
	\rput(36,10){1}
	\rput(38,10){1}
	\rput(40,10){0}
	\rput(42,10){1}
	\rput(44,10){1}
	\rput(46,10){0}
	\rput(48,10){1}
	\rput(50,10){1}
	\rput(52,10){1}
	\rput(54,10){1}
	\rput(56,10){1}
	\rput(58,10){0}
	\rput(60,10){0}
	\rput(62,10){0}
	\rput(64,10){0}
	\rput(66,10){0}
	\rput(68,10){1}
	\rput(70,10){0}
	\rput(72,10){1}
	\rput(74,10){1}
	\rput(76,10){0}
	\rput(78,10){1}
	\psline{->}(50,5)(50,7.5)
	\psline{->}(50,15)(50,12.5)
	\psline{->}(10,5)(10,7.5)
	\psline{->}(10,15)(10,12.5)
}{Example of the generation of a new entity by
reproduction in the Genetic default algorithm. Note that the identical bits in both parents (in grey) are also present in their son. The rest of the bits are random}{FigReproduction}

\subsection{Adaptation algorithm}

Another algorithm is included in Genetic called ``adaptation'' although, in the
biological sense, it would be rather be a smooth mutation. First, one of the
variables codified in the genome is randomly selected with uniform probability.
Then, a bit is randomly chosen assuming a probability linearly decreasing with
the significance of the bit. The new individual receives a copy of the parents
genome with the selected bit inverted. Figure~\ref{FigAdaptation} contains an
example.

\psset{unit=1mm}
\PSPICTURE{-30}{-7.5}{80}{30}
{
	\scriptsize
	\rput(-10,17.5){Parent}
	\rput(15,23){Variable 1}
	\psframe(0,15)(30,20)
	\rput(40,23){Variable 2}
	\psframe(30,15)(50,20)
	\rput(65,23){Variable 3}
	\psline{->}(55,28)(65,28)(65,26)
	\rput(35,28){Random selection of a variable}
	\psframe(55,21)(75,26)
	\psframe(50,15)(80,20)
	\psline{->}(10,12)(0,12)
	\rput(5,9){Less}
	\rput(5,6){significant}
	\rput(5,3){bit}
	\psline{->}(20,12)(30,12)
	\rput(25,9){More}
	\rput(25,6){significant}
	\rput(25,3){bit}
	\rput(2,17.5){1}
	\rput(4,17.5){0}
	\rput(6,17.5){0}
	\rput(8,17.5){1}
	\rput(10,17.5){0}
	\rput(12,17.5){0}
	\rput(14,17.5){1}
	\rput(16,17.5){1}
	\rput(18,17.5){1}
	\rput(20,17.5){1}
	\rput(22,17.5){1}
	\rput(24,17.5){1}
	\rput(26,17.5){0}
	\rput(28,17.5){1}
	\rput(32,17.5){1}
	\rput(34,17.5){0}
	\rput(36,17.5){0}
	\rput(38,17.5){0}
	\rput(40,17.5){0}
	\rput(42,17.5){0}
	\rput(44,17.5){0}
	\rput(46,17.5){0}
	\rput(48,17.5){0}
	\rput(52,17.5){1}
	\rput(54,17.5){1}
	\rput(56,17.5){1}
	\rput(58,17.5){1}
	\rput(60,17.5){0}
	\rput(62,17.5){1}
	\rput(64,17.5){0}
	\rput(66,17.5){0}
	\rput(68,17.5){0}
	\rput(70,17.5){0}
	\rput(72,17.5){1}
	\rput(74,17.5){1}
	\rput(76,17.5){1}
	\rput(78,17.5){1}
	\rput(65,10){Probability of selection}
	\rput(65,7){of a bit}
	\psframe[fillcolor=gray,fillstyle=solid](77,0)(79,0.5)
	\psframe[fillcolor=gray,fillstyle=solid](75,0)(77,1.0)
	\psframe[fillcolor=gray,fillstyle=solid](73,0)(75,1.5)
	\psframe[fillcolor=gray,fillstyle=solid](71,0)(73,2.0)
	\psframe[fillcolor=gray,fillstyle=solid](69,0)(71,2.5)
	\psframe[fillcolor=gray,fillstyle=solid](67,0)(69,3.0)
	\psframe[fillcolor=gray,fillstyle=solid](65,0)(67,3.5)
	\psframe[fillcolor=gray,fillstyle=solid](63,0)(65,4.0)
	\psframe[fillcolor=gray,fillstyle=solid](61,0)(63,4.5)
	\psframe[fillcolor=gray,fillstyle=solid](59,0)(61,5.0)
	\psframe[fillcolor=gray,fillstyle=solid](57,0)(59,5.5)
	\psframe[fillcolor=gray,fillstyle=solid](55,0)(57,6.0)
	\psframe[fillcolor=gray,fillstyle=solid](53,0)(55,6.5)
	\psframe[fillcolor=gray,fillstyle=solid](51,0)(53,7.0)
	\rput(-10,-5){Son}
	\psframe(0,-2.5)(30,-7.5)
	\psframe(30,-2.5)(50,-7.5)
	\psframe(50,-2.5)(80,-7.5)
	\rput(2,-5){1}
	\rput(4,-5){0}
	\rput(6,-5){0}
	\rput(8,-5){1}
	\rput(10,-5){0}
	\rput(12,-5){0}
	\rput(14,-5){1}
	\rput(16,-5){1}
	\rput(18,-5){1}
	\rput(20,-5){1}
	\rput(22,-5){1}
	\rput(24,-5){1}
	\rput(26,-5){0}
	\rput(28,-5){1}
	\rput(32,-5){1}
	\rput(34,-5){0}
	\rput(36,-5){0}
	\rput(38,-5){0}
	\rput(40,-5){0}
	\rput(42,-5){0}
	\rput(44,-5){0}
	\rput(46,-5){0}
	\rput(48,-5){0}
	\rput(52,-5){1}
	\rput(54,-5){1}
	\rput(56,-5){0}
	\rput(58,-5){1}
	\rput(60,-5){0}
	\rput(62,-5){1}
	\rput(64,-5){0}
	\rput(66,-5){0}
	\rput(68,-5){0}
	\rput(70,-5){0}
	\rput(72,-5){1}
	\rput(74,-5){1}
	\rput(76,-5){1}
	\rput(78,-5){1}
	\psline{->}(-10,15)(-10,-2.5)
	\rput(-20,6.25){Adaptation}
	\psframe(55,-7.5)(57,-2.5)
	\psframe(55,15)(57,20)
}{Example of the generation of a new individual from a parent by adaptation}
{FigAdaptation}

This algorithm is rather similar to the mutation algorithm previously described but, since the probability to affect bits less significant is larger, so is the probability to produce smaller changes.

\subsection{Parallelization}

This method is also easily parallelizable following a similar scheme to the
iterative algorithm, as it can be seen in the
figure~\ref{FigGeneticParallelization}.

\psset{xunit=0.5mm,yunit=0.5mm}
\PSPICTURE{-100}{-185}{100}{-15}
{
	\tiny
	\rput(0,-15){1st generation:}
	\rput(0,-20){Generation of $N_{population}$ empirical parameters sets}
	\psframe(-60,-25)(60,-10)
	\psline{->}(0,-25)(-60,-30)
	\psline{->}(0,-25)(0,-30)
	\psline{->}(0,-25)(60,-30)
	\rput(-60,-35){1st task:}
	\rput(-60,-40){$N_{population}/N_{tasks}$ simulations}
	\psframe(-100,-30)(-20,-45)
	\rput(0,-37.5){$\cdots$}
	\rput(60,-35){$N_{tasks}$-th task:}
	\rput(60,-40){$N_{population}/N_{tasks}$ simulations}
	\psframe(20,-30)(100,-45)
	\psline{->}(-60,-45)(0,-50)
	\psline{->}(0,-45)(0,-50)
	\psline{->}(60,-45)(0,-50)
	\rput(0,-55){Getting $N_{survival}$ empirical parameters sets}
	\psframe(-55,-50)(55,-60)
	\psline{->}(0,-60)(0,-65)
	\rput(0,-70){2nd generation:}
	\rput(0,-75){Generation of $N_{new}$ empirical parameters sets}
	\psframe(-55,-80)(55,-65)
	\psline{->}(0,-80)(-60,-85)
	\psline{->}(0,-80)(0,-85)
	\psline{->}(0,-80)(60,-85)
	\rput(-55,-90){1st task:}
	\rput(-55,-95){$N_{new}/N_{tasks}$ simulations}
	\psframe(-90,-85)(-20,-100)
	\rput(0,-92.5){$\cdots$}
	\rput(55,-90){$N_{tasks}$-th task:}
	\rput(55,-95){$N_{new}/N_{tasks}$ simulations}
	\psframe(20,-85)(90,-100)
	\psline{->}(-55,-100)(0,-105)
	\psline{->}(0,-100)(0,-105)
	\psline{->}(55,-100)(0,-105)
	\rput(0,-110){Getting $N_{survival}$ empirical parameters sets}
	\psframe(-55,-105)(55,-115)
	\psline{->}(0,-115)(0,-120)
	\rput(0,-125){$\cdots$}
	\psline{->}(0,-130)(0,-135)
	\rput(0,-140){$N_{generations}$-th generation:}
	\rput(0,-145){Generation of $N_{new}$ empirical parameters sets}
	\psframe(-55,-150)(55,-135)
	\psline{->}(0,-150)(-60,-155)
	\psline{->}(0,-150)(0,-155)
	\psline{->}(0,-150)(60,-155)
	\rput(-55,-160){1st task:}
	\rput(-55,-165){$N_{new}/N_{tasks}$ simulations}
	\psframe(-90,-155)(-20,-170)
	\rput(0,-162.5){$\cdots$}
	\rput(55,-160){$N_{tasks}$-th task:}
	\rput(55,-165){$N_{new}/N_{tasks}$ simulations}
	\psframe(20,-155)(90,-170)
	\psline{->}(-55,-170)(0,-175)
	\psline{->}(0,-170)(0,-175)
	\psline{->}(55,-170)(0,-175)
	\rput(0,-180){Getting optimal empirical parameters set}
	\psframe(-55,-175)(55,-185)
}{Flowchart of the parallelization scheme implemented in Genetic for the genetic
method}{FigGeneticParallelization}

\bibliography{bib}

\end{document}
