\documentclass[review,authoryear]{elsarticle}

\usepackage[utf8]{inputenc}
\usepackage{listings}
\usepackage{pstricks}
\usepackage{multido}
\usepackage{amsfonts}
\usepackage{url}
\usepackage{multirow}

\usepackage{lineno}
\linenumbers

\newcommand{\EQ}[2]
{\begin{equation}#1\label{#2}\end{equation}}

\newcommand{\PICTURE}[5]
{
	\begin{figure}[ht!]
		\centering
		\begin{picture}(#1,#2)
			#3
		\end{picture}
		\caption{#4.\label{#5}}
	\end{figure}
}

\newcommand{\PSPICTURE}[7]
{
	\begin{figure}[ht!]
		\centering
		\pspicture(#1,#2)(#3,#4)
			#5
		\endpspicture
		\caption{#6.\label{#7}}
	\end{figure}
}

\newcommand{\TABLE}[5]
{
	\begin{table}[ht!]
		\centering
		\caption{#4.\label{#5}}
		#1
		\begin{tabular}{#2}
			#3
		\end{tabular}
	\end{table}
}

\newcommand{\FIG}[3]
{
	\begin{figure}[ht!]
		\centering
		\includegraphics[width=\textwidth]{#1}
		\caption{#2.\label{#3}}
	\end{figure}
}

\newcommand{\PLOT}[3]
{
	\begin{figure}[ht!]
		\centering
		\includegraphics{#1}
		\caption{#2.\label{#3}}
	\end{figure}
}

\newcommand{\FIGII}[4]
{
	\begin{figure}[ht!]
		\centering
		\begin{tabular}{c}
			\includegraphics{#1} \\ \includegraphics{#2}
		\end{tabular}
		\caption{#3.\label{#4}}
	\end{figure}
}

\newcommand{\PLOTII}[4]
{
	\begin{figure}[ht!]
		\centering
		\begin{tabular}{cc}
			\includegraphics{#1} & \includegraphics{#2}
		\end{tabular}
		\caption{#3.\label{#4}}
	\end{figure}
}

\newcommand{\FIGIII}[5]
{
	\begin{figure}[ht!]
		\centering
		\begin{tabular}{cc}
			\includegraphics{#1} & \includegraphics{#2} \\
			\multicolumn{2}{c}{\includegraphics{#3}}
		\end{tabular}
		\caption{#4.\label{#5}}
	\end{figure}
}

\newcommand{\FIGIV}[6]
{
	\begin{figure}[ht!]
		\centering
		\begin{tabular}{cc}
			\includegraphics{#1} & \includegraphics{#2} \\
			\includegraphics{#3} & \includegraphics{#4}
		\end{tabular}
		\caption{#5.\label{#6}}
	\end{figure}
}

\newcommand{\FIGVI}[8]
{
	\begin{figure}[ht!]
		\centering
		\begin{tabular}{cc}
			\includegraphics{#1} & \includegraphics{#2} \\
			\includegraphics{#3} & \includegraphics{#4} \\
			\includegraphics{#5} & \includegraphics{#6}
		\end{tabular}
		\caption{#7.\label{#8}}
	\end{figure}
}

\newcommand{\ABS}[1]{\left|#1\right|}
\newcommand{\C}[1]{\left[#1\right]}
\newcommand{\MATRIX}[2]{\PA{\begin{array}{#1}#2\end{array}}}
\newcommand{\PA}[1]{\left(#1\right)}
\newcommand{\LL}[1]{\left\{#1\right\}}

\bibliographystyle{elsarticle-harv}

\begin{document}

\title{MPCOTool: an open source software to supply empirical parameters
required in simulation models}

\author[eead,bifi]{J. Burguete\corref{cor1}}
\ead{jburguete@eead.csic.es}

\author[eead]{B. Latorre}
\ead{borja.latorre@csic.es}

\author[kit]{S. Ambroj}
\ead{samuel.ambroj@kit.edu}

\author[unizar]{A. Lacasta}
\ead{alacasta@unizar.es}

\author[eead]{S. Ouazaa}
\ead{sofiane.ouazaa@eead.csic.es}

\author[eead]{N. Zapata}
\ead{v.zapata@csic.es}

\author[unizar]{P. García-Navarro}
\ead{pigar@unizar.es}

\cortext[cor1]{Corresponding author}

\address[eead]{Soil and Water, EEAD / CSIC.
P.O. Box 13034, 50080~Zaragoza, Spain.}
\address[bifi]{BIFI: Instituto de Biocomputación y Física de Sistemas Complejos,
Universidad de Zaragoza.
Mariano Esquillor, Edificio I+D, 50009~Zaragoza, Spain.}
\address[kit]{Steinbuch Centre for Computing (SCC),
Karlsruhe Institute of Technology (KIT).
KIT-Campus Nord, Hermann von Helmholtzplatz 1, 76344 Eggenstein - Leopoldshafen,
Germany.}
\address[unizar]{Fluid Mechanics, LIFTEC, CSIC-Universidad de Zaragoza.
María de Luna 3, 50018~Zaragoza, Spain.}

\begin{keyword}
optimization, calibration, simulation, model, software, irrigation, sprinkler,
furrow, canal
\end{keyword}

\begin{abstract}
The present work describes MPCOTool, a new software program to perform
optimization or calibration of empirical parameters required in the
formulation of numerical simulation models. The structure is such that it can be
easily adapted to different external simulation codes.
One genetic algorithm, two brute force optimization algorithms (sweep and
Monte-Carlo) and an iterative algorithm to improve the brute force methods are
included as alternative methods.
Parallel computations are enabled in a simple way so that the work load can be
distributed among the different processors available in one computer or in
multiple computers of a cluster.
The software optimization methods are analysed in six standard analytical test
functions.
The MPCOTool usage and possibilities are illustrated by showing four practical
applications in agriculture: optimization of a canal management; calibration of
the empirical coefficients in a surface irrigation model; calibration in a
ballistic sprinkler irrigation model and calibration in an irrigation engines
movement model.
This software is open source and is distributed with a BSD (Berkeley Software
Distribution) type license.
\end{abstract}

\maketitle

\section{Introduction}

Calibration is related to the optimization process of finding the minimum of a
function usually defined as a relation between the desired value of a quantity
and that supplied by a suitable simulation model. This process is more necessary
when simplifications on models are done as some of the
physical processes are hidden in black box parameters. Deterministic models are
sensitive to parameters and their ability increases when the quality of the
calibration improves. In some way, the model may acquire a true predictive
character when calibrated. The calibration can be understood as an optimization
process where the error between the estimation of the model and the data set is
minimized \citep{Lacasta15}.

There are many fields where calibration is required. Traditionally, fields such
as hydrology or weather forecasting have used mathematical models with empirical
parameters which require to be adjusted. For example, watershed models usually
estimates initial parameter values for sediment fractions, instream water
temperature or infiltration rates \citep{Duan04}. Within agriculture, there are
many phenomena that can be modelled using differential equations that
participate in conservation laws
\citep{Playan06,JaviSurcos2,Ebrahimiam13,Ouazaa14,Ouazaa15,SedagatdoostEbraimian15}.
The application of
mathematical models to describe physical processes is helpful to perform
simulations of possible scenarios using computational facilities. Despite the
quality of these mathematical models for predictive purposes, calibration is
usually required to provide them useful properties. The application of the
shallow-water equations for the simulation of open-channel flow, for instance,
has been widely used, in particular for irrigation water delivery analysis. To
complete the equations with regulation elements, it is accepted that some
simplifications can be applied. These simplifications usually include parameters
that make possible to model simpler the phenomena that occur on those regulation
elements.

Because of the mathematical model, differential equations constrained
optimization may be performed using two optimizer families: gradient based
methods and gradient-free optimizers. While the latter do not require gradient
information to perform the optimization, the former must have information about
the variation of the objective with respect to the controlled variable
\citep{Lacasta15}. Therefore, although gradient based methods exhibit superior
convergences, they are more difficult to implement in general purpose software.
Nonetheless, when calibration is understood as the adjustment of empirical
values, gradient-based methods may fail due to the location of local minimums.
Stochastic based optimization algorithms (as sweep, Monte-Carlo or genetic) are
not affected by local minimum presence. 
%%%%%%%%%%%%%
Detailed analysis of the properties and performance of several stochastic
optimization algorithms can be seen, for instance, in \citet{Back96} or in
\citet{HauptHaupt04}.
%%%%%%%%%%%%%
Applications of these methods in
agriculture can be seen for instance in \citet{JaviSurcos2} (sweep),
\citet{Ouazaa15} (Monte-Carlo) or \citet{Ebrahimiam13} (genetic). Moreover,
these methods are easily parallelizable increasing the performance when executed
on machines with multiple processors. In \cite{Lacasta15} a deeper comparison of
both, gradient based and stochastic optimization methods can be found.

In this work MPCOTool, the Multi-Purposes Calibration and Optimization Tool
\citep{MPCOToolGit}, a software to perform
optimization or calibration of empirical parameters required in simulation
models, is presented. It is open source with a BSD type license. All input data
files used in the manuscript are also free and they can be downloaded in the
cited web page.

The present paper is organized as follows: First, the concepts of calibration
and optimization are presented as the main goal. Then the methods used to
achieve them in MPCOTool are described. The tool structure and organization
are next presented in detail. After, the performance is demonstrated using
four different applications of interest in agriculture. Finally, the conclusions
are drawn.

\section{Calibration and optimization}

Calibration can be considered a particular case of optimization
\citep{WrightNocedal99}, probably the most widely applied. It usually deals with
setting the parameters that allow to represent correctly the behavior of a
component or model. It is very common to describe physical phenomena using
complex mathematical models including all the possible scales. Nevertheless, it
is very useful to simplify them including adjustable parameters that enclose
smaller scales.

Optimization can be understood as the minimization process of some functional
that evaluates the objective of a model. Therefore, a functional $J$ must be
defined in order to evaluate the deviation between your model results
$\mathbf{x}$ and your objectives $\mathbf{x}_o$, with
$\mathbf{x},\mathbf{x}_o\in\mathbb{R}^n$ real vectors of $n\ge 1$
components ($x_i$ and $x_{o,i}$ respectively) and
$J:\mathbb{R}^n \rightarrow \mathbb{R}$. 
Infinite ways of defining $J$ can be used, for example penalizing different
variables with different weights according to their importance to our
objectives. The aim is to find the minimum of this functional:
\EQ{\min_{\mathbf{x}}\;J\PA{\mathbf{x}}.}{EqFunctionalMin}

In order to meet the optimal solution it is important to keep in mind that
$\mathbf{x}\equiv\mathbf{x}\PA{\mathbf{y}}$ may be directly or indirectly
related with another tunable quantity: $\mathbf{y}\in\mathbb{R}^m$  ($m$
parameters which can be optimized in the model). The complexity of the
optimization process comes from the relation that may be established between the
model and this tunable set of parameters. Bearing in mind that relation, the
optimization is the minimization of the functional by means of the modification
of those parameters. Moreover, those parameters are usually defined in a range
$y_i\in\PA{y_{i,min},\,y_{i,max}}$ so the minimization problem is formally
defined as:
\EQ
{
	\mathbf{y}_o=\arg\min_{\mathbf{y}}J\PA{\mathbf{x}\PA{\mathbf{y}}},
}{EqParametersOptimal}
being $\mathbf{y}_o$ the optimum set of parameters obtained by the model.
MPCOTool allows to achieve them by means of different methods. In addition,
the metric used to evaluate the functional is open and may be defined by the
user.

\section{Methods}

The optimization methods implemented in MPCOTool are next presented.
Details of the algorithm and parallelization characteristics, as well as
flowcharts, examples and diagrams of all methods described in this section can
be seen in the user manual provided with the software.

\subsection{Sweep brute force method (SW)}

The sweep brute force method finds the optimal set of parameters within a solution region by dividing it into regular subdomains. To find the optimal solution, the domain interval $x_i \in \PA{x_{i,min},\,x_{i,max}}$ is first defined for each variable $x_i$. Then, a regular partition in  $N_{x,i}$ subintervals is made. This method is the most obvious and simplest algorithm of optimization. Moreover, it is so old that it is difficult to find references of first applications. Note that the computational cost increases exponentially as the number of variables to optimize grows.

Brute force algorithms present low convergence rates but they are strongly
parallelizable because every simulation is completely independent. If the
computer, or the computers cluster, can execute $N_{tasks}$ parallel tasks
every task do $N_{total}/N_{tasks}$ simulations, obviously taking into account
rounding effects (every task has to perform a natural number of simulations).

\subsection{Monte-Carlo method (MC)}

Monte-Carlo based methods run $N_s$ simulations using aleatory values of the
variables assuming uniform probability within the extreme values range. This is
another old brute force method attributed to different authors. In
\citet{AtanassovDimov08} an interesting analysis of this method is presented.
The algorithm is parallelizable in the same way as sweep algorithm.

\subsection{Iterative algorithm (IT) applied to brute force methods}

MPCOTool allows to iterate both SW or MC brute force methods in
order to seek convergence. In this case, the best results from the previous
iteration are used to force new intervals in the variables for the following
iteration. Then for $N_b^j$, the subset of the best simulation results in
the $j$-th iteration, the following quantities are defined:
\begin{description}
\item[$\displaystyle x_{\max}^b=\max_{i\in N_b}x_i^j$]: Maximum value of
	variable $x$ in the subset of the best simulation results from the $j$-th
	iteration.
\item[$\displaystyle x_{\min}^b=\max_{i\in N_b}x_i^j$]: Minimum value of
	variable $x$ in the subset of the best simulation results from the $j$-th
	iteration.
\end{description}
A new interval in the variable $x$ is defined to build the optimization values in the next $(j+1)$ iteration so that:
\EQ{x_i^{j+1}\in\left[x_{\min}^{j+1},\;x_{\max}^{j+1}\right],}
{EqIterationInterval}
with:
\[
	\mathrm{SW}\;\Rightarrow\;\left\{\begin{array}{c}
	\displaystyle
	x_{\max}^{j+1}=x_{\max}^b+\frac{x_{\max}^j-x_{\min}^j}{N_x-1}\,tol,\\
	\displaystyle
	x_{\min}^{j+1}=x_{\min}^b-\frac{x_{\min}^j-x_{\min}^j}{N_x-1}\,tol,\\
	\end{array}\right.
\]
\EQ
{
	\mathrm{MC}\;\Rightarrow\;\left\{\begin{array}{c}
	\displaystyle x_{\max}^{j+1}=\frac{x_{\max}^b+x_{\min}^b
	+\left(x_{\max}^b-x_{\min}^b\right)(1+tol)}{2},\\
	\displaystyle x_{\min}^{j+1}=\frac{x_{\max}^b+x_{\min}^b
	-\left(x_{\max}^b-x_{\min}^b\right)(1+tol)}{2},
	\end{array}\right.
}{EqIterationTolerance}
being $tol$ a tolerance factor increasing the size of the variable intervals to
simulate the next iteration. Note that this factor affect in different manner to
SW and MC algorithms. The method is repeated $N_i$ times.

The iterative algorithm can be also easily parallelized. However, this method is
less parallelizable than pure brute force methods because the parallelization
has to be performed for each iteration.

\subsection{Direction search method (DS)}

Brute force optimization methods, SW and MC, can be also combined
with a direction search algorithm. Defining the vector $\vec{r}_i$ as the optime
variables combination obtained in the $i$-th step, $\vec{r}_1$ as the optime
varaibles combination vector obtained by the brute force method and defining
the vector $\vec{s}_i$ as:
\EQ
{
	\vec{s}_1=\vec{0},\qquad
	\vec{s}_i=(1-rel)\,\vec{s}_{i-1}+rel\,\Delta\vec{r}_{i-1},
}{Eqs}
with $\Delta\vec{r}_{i-1}=\vec{r}_i+\vec{r}_{i-1}$ and $rel$ the
relaxation parameter, the DS method checks $N_e$
variable combinations and choice the optimum as:
\EQ
{
	\vec{r}_{i+1}=\mathrm{optime}\PA{\vec{r}_i,\;\vec{r}_i+\vec{s}_i+\vec{t}_j},
	\;j=1,\cdots,N_e.
}{EqDirection}
If the step does not improve the optimum ($\vec{r}_i=\vec{r}_{i+1}$) then the
direction step vectors $\vec{t}_j$ are divided by two and $\vec{s}_{i+1}$ is set
to zero. The method is iterated $N_{st}$ times.

Although gradient based method gets the fastest convergence, is the method in
MPCOTool that obtains the least advantages of parallelization. The method is
almost sequential and parallelization only can be performed for each step in
the $N_e$ simulations to estimate the gradient.

MPCOTool uses two methods to build the $\vec{t}_j$ vectors:

\subsubsection{Coordinates descent (CD)}

This method builds the $\vec{t}_j$ vectors by increasing or decreasing only one
variable:
\EQ
{
	\vec{t}_1=\MATRIX{c}{st_1\\0\\\vdots\\0},\quad
	\vec{t}_2=\MATRIX{c}{-st_1\\0\\\vdots\\0},\quad
	\cdots\quad,\vec{t}_{N_e}=\MATRIX{c}{0\\0\\\vdots\\-st_{N_v}},
}{EqtDescent}
being $st_j$ the initial step size for the $j$-th variable defined by the user
in the main input file. The number of estimates in this method depends on the
variables number:
\EQ{N_e=2\,N_v}{EqNestimatesDescent}

\subsubsection{Random (RA)}

The vectors $\vec{t}_j$ are built randomly as:
\EQ
{
	\vec{t}_j=\MATRIX{c}{\PA{1-2\,r_{j,1}}\,st_1\\\vdots\\
	\PA{1-2\,r_{j,N_v}}\,st_{N_v}},
}{EqtRandom}
with $r_{j,k}\in[0,1)$ random numbers.

\subsection{Genetic method (GE)}

MPCOTool also offers the use of a genetic method Genetic \citep{genetic} with its default algorithms.
It is inspired on the ideas in \citet{gaul}, but it has been fully reprogrammed involving more modern external libraries.
The code in Genetic is also open source under a BSD license.

\subsubsection{The genome}

The variables to calibrate/optimize are coded in Genetic using a bit chain: the
genome. The larger the number of bits assigned to a variable the higher the resolution.
The number of bits assigned to each variable, and therefore the genome size, is fixed and the same for all the 
simulations.
The value assigned to a variable $x$ is determined by the allowed extreme values $x_{\min}$ and $x_{\max}$, the binary number assigned in the genome to variable $I_x$ and by the number of bits assigned to variable $N_x$ according to
the following formula:
\EQ{x=x_{\min}+\frac{I_x}{2^{N_x}}\,\left(x_{\max}-x_{\min}\right).}{EqGenome}

\subsubsection{Survival of the best individuals}

In a population with $N_p$ individuals, in the first generation all the cases are simulated. The input variables are
taken from the genome of each individual. Next, in every generation, $N_p\,R_m$ individuals are generated by mutation, $N_p\,R_r$ individuals are generated by reproduction and $N_p\,R_a$ individuals are generated by adaptation, obviously
taking into account rounding. On second and further generations only simulations
associated to this new individuals ($N_{new}$) have to be run:
\EQ{N_{new}=N_p\,\left(R_m+R_r+R_a\right).}{EqNew}
Then, total number of simulations performed by the genetic algorithm is:
\EQ{N_{total}=N_p+\left(N_g-1\right)\,N_{new},}{EqGeneticNumber}
with $N_g$ the number of generations of new entities.
The individuals of the former population that obtained lower values in the evaluation function are replaced so that the best $N_{survival}$ individuals survive:
\EQ{N_{survival}=N_p-N_{new}.}{EqSurvival}
Furthermore, the ancestors to generate new individuals are chosen among the surviving population. Obviously, to have survival population, the following condition has to be enforced:
\EQ{R_m+R_r+R_a<1}{EqSurvivalCondition}
MPCOTool uses a default aleatory criterion in Genetic, with a probability linearly decreasing with the ordinal in the ordered set of surviving individuals.

\subsubsection{Mutation algorithm}

In the mutation algorithm an identical copy of the parent genome is made except for a bit, randomly chosen with uniform probability, which is inverted.

\subsubsection{Reproduction algorithm}

The default algorithm in Genetic selects two different parents with one of the least errors after the 
complete simulation of one generation. 
A new individual is then generated by sharing the common bits of both parents and a random choice in the others.
The new child has the same number of bits as the parents and different genome.

\subsubsection{Adaptation algorithm}

Another algorithm is included in Genetic called "adaptation" although, in the
biological sense, it would be rather be a smooth mutation. First, one of the
variables codified in the genome is randomly selected with uniform probability.
Then, a bit is randomly chosen assuming a probability linearly decreasing with
the significance of the bit. The new individual receives a copy of the parent
genome with the selected bit inverted.

This algorithm is rather similar to the mutation algorithm previously described but, since the probability to affect bits less significant is larger, so is the probability to produce smaller changes.

\subsubsection{Parallelization}

This method is also easily parallelizable following a similar scheme to the
iterative algorithm although, in the same way, pure brute force methods allow
better parallelization because genetic algorithm requires one for each
generation.

\section{Implementation}

\subsection{Organization of MPCOTool}

Let us assume that $N_{par}$ empirical parameters are sought desired so
that the results from a simulation model are the best fit to $N_{exp}$
experimental data and that the simulator requires $N_{in}$ input files. The
structure followed by MPCOTool is summarized in the \emph{main input file},
where both $N_{exp}$ and $N_{in}$ are specified. Furthermore, it
contains the extreme values of the empirical parameters and the chosen
optimization algorithm. Then, MPCOTool reads the
$N_{exp}\,N_{in}$ templates to build the simulator input files
replacing key labels by empirical parameter values created by the optimization
algorithm. There are two options: either the simulator compares directly the
simulation results with the \emph{experimental data file}, hence generating a
file with the value of the error, or an external program called \emph{evaluator}
is invoked to compare with the \emph{experimental data file} and to produce the
error value. In both cases this error value is saved in an
\emph{objective value file}. Then for each experiment, an objective value $o_i$
is obtained. The final value of the objective function ($J$) associated with the
experiments set can be calculated by four different error norms:
\EQ{L_2:\quad J=\sqrt{\sum_{i=1}^{N_{experiments}}\ABS{w_i\,o_i}^2},}
{EqObjectiveFunctionLII}
\EQ{L_\infty:\quad J=\max_{i=1}^{N_{experiments}}\ABS{w_i\,o_i},}
{EqObjectiveFunctionLi}
\EQ{L_p:\quad J=\sqrt[p]{\sum_{i=1}^{N_{experiments}}\ABS{w_i\,o_i}^p},}
{EqObjectiveFunctionLp}
\EQ{L_1:\quad J=\sum_{i=1}^{N_{experiments}}\ABS{w_i\,o_i},}
{EqObjectiveFunctionLI}
with $w_i$ the weight associated to the $i$-th experiment, specified in the
\emph{main input file}. Note that these error norms are used to combine the
error $o_i$ obtained for each experiment. The user is completely free to define
the objective function for every experiment. Figure~\ref{FigStructure} is a
sketch of the structure.
\psset{xunit=0.4mm,yunit=0.4mm}
\PSPICTURE{-20}{-95}{280}{55}
{
	\tiny
	\rput(15,50){Main input file}
	\psframe(-20,45)(50,55)
	\psline{->}(50,50)(60,50)
	\rput(15,25){1st template file}
	\psframe(-20,20)(50,30)
	\psline{->}(50,25)(60,25)
	\psline[linestyle=dotted,dotsep=1pt]{->}(60,25)(90,25)
	\rput(15,15){$\cdots$}
	\rput(15,5){$n$-th template file}
	\psframe(-20,0)(50,10)
	\psline{->}(50,5)(60,5)
	\psline[linestyle=dotted,dotsep=1pt]{->}(60,5)(90,5)
	\rput(15,-35){$\cdots$}
	\rput(15,-75){$(N\,n)$-th template file}
	\psframe(-20,-70)(50,-80)
	\psline{->}(50,-75)(60,-75)
	\psline[linestyle=dotted,dotsep=1pt]{->}(60,-75)(90,-75)
	\rput(75,50){MPCOTool}
	\psframe(60,-95)(90,55)
	\psline{->}(90,25)(100,25)
	\psline{->}(90,5)(100,5)
	\psline{->}(90,-55)(100,-55)
	\psline{->}(90,-75)(100,-75)
	\rput(120,5){$n$-th input file}
	\psframe(100,0)(140,10)
	\psline{->}(140,5)(150,5)
	\rput(120,15){$\cdots$}
	\rput(120,25){1st input file}
	\psframe(100,20)(140,30)
	\psline{->}(140,25)(145,25)(145,5)
	\rput(185,5){Simulator}
	\psframe(150,0)(220,10)
	\psline[linestyle=dashed,dash=2pt 1pt]{->}(185,10)(185,20)
	\psline[linestyle=dashed,dash=2pt 1pt]{->}(220,5)(230,7.5)
	\rput(185,25){Results file}
	\psframe[linestyle=dashed,dash=3pt 1pt](150,20)(220,30)
	\psline[linestyle=dashed,dash=2pt 1pt]{->}(220,25)(230,30)
	\rput(185,45){Experimental data file}
	\psframe(150,40)(220,50)
	\psline[linestyle=dashed,dash=2pt 1pt]{->}(220,45)(230,30)
	\psline[linestyle=dashed,dash=2pt 1pt]{->}(150,45)(145,45)(145,25)
	\rput(250,30){Evaluator}
	\psline[linestyle=dashed,dash=2pt 1pt]{->}(250,25)(250,15)
	\psframe[linestyle=dashed,dash=3pt 1pt](230,25)(270,35)
	\rput(250,10){Objective}
	\rput(250,5){value file}
	\psframe(230,0)(270,15)
	\psline{->}(270,7.5)(280,7.5)(280,-90)(90,-90)
	\rput(15,-90){Objective function value}
	\psframe(-20,-95)(50,-85)
	\psline{->}(60,-90)(50,-90)
	\psline[linestyle=dotted,dotsep=1pt]{->}(90,-90)(60,-90)
	\rput(120,50){1st experiment}
	\psframe[linestyle=dotted](95,-5)(275,55)
	\rput(185,-15){$\cdots$}
	\rput(120,-75){$n$-th input file}
	\psframe(100,-80)(140,-70)
	\psline{->}(140,-75)(150,-75)
	\rput(120,-65){$\cdots$}
	\rput(120,-55){1st input file}
	\psframe(100,-60)(140,-50)
	\psline{->}(140,-55)(145,-55)(145,-75)
	\rput(185,-75){Simulator}
	\psframe(150,-80)(220,-70)
	\psline[linestyle=dashed,dash=2pt 1pt]{->}(185,-70)(185,-60)
	\psline[linestyle=dashed,dash=2pt 1pt]{->}(220,-75)(230,-72.5)
	\rput(185,-55){Results file}
	\psframe[linestyle=dashed,dash=3pt 1pt](150,-60)(220,-50)
	\psline[linestyle=dashed,dash=2pt 1pt]{->}(220,-55)(230,-50)
	\rput(185,-35){Experimental data file}
	\psframe(150,-40)(220,-30)
	\psline[linestyle=dashed,dash=2pt 1pt]{->}(220,-35)(230,-50)
	\psline[linestyle=dashed,dash=2pt 1pt]{->}(150,-35)(145,-35)(145,-55)
	\rput(250,-50){Evaluator}
	\psline[linestyle=dashed,dash=2pt 1pt]{->}(250,-55)(250,-65)
	\psframe[linestyle=dashed,dash=3pt 1pt](230,-55)(270,-45)
	\rput(250,-70){Objective}
	\rput(250,-75){value file}
	\psframe(230,-80)(270,-65)
	\psline(270,-72.5)(280,-72.5)
	\rput(120,-30){$N$-th experiment}
	\psframe[linestyle=dotted](95,-85)(275,-25)
}{Flowchart of the interactions among MPCOTool, the input files and the
simulation and evaluation programs to produce an objective function value for
each empirical parameters combination generated by the optimization algorithm}
{FigStructure}

The whole process is repeated for each combination of empirical parameters generated by the optimization algorithm. Furthermore, MPCOTool automatically parallelizes the simulations using all the available computing resources.

The required format for the main input file and the template files are described in the provided user manual.

\subsection{Command line format}

The code of MPCOTool is written in C code using standard open source libraries. The software can be compiled in the most widely used operative systems (Windows, Linux, FreeBSD, ...). Instructions to build the executable can be read in the user manual. The optional arguments for the command line will be typed in square brackets.

\begin{itemize}

\item Command line in sequential mode (where X is the number of threads to
execute and S is a seed for the pseudo-random numbers generator):
\begin{lstlisting}[language=bash,basicstyle=\scriptsize]
> ./mpcotoolbin [-nthreads X] [-seed S] input_file.xml
[result_file] [variables_file]
\end{lstlisting}

\item Command line in parallelized mode (where in this case X is the number of
threads to open for every node):
\begin{lstlisting}[language=bash,basicstyle=\scriptsize]
> mpirun [MPI options] ./mpcotoolbin [-nthreads X] [-seed S]
input_file.xml [result_file] [variables_file]
\end{lstlisting}

\item The syntax of the simulator program has to be:
\begin{lstlisting}[language=bash,basicstyle=\scriptsize]
> ./simulator_name input_file_1 [input_file_2] [...] output_file
\end{lstlisting}
There are two options for the output file. It can begin with a number indicating
the objective function value or it can be a results file that has to be
evaluated by an external program (the evaluator) comparing with an experimental
data file.

\item In the last option of the former point, the syntax of the program to
evaluate the objective function has to be (where the results file has to begin
with the objective function value):
\begin{lstlisting}[language=bash,basicstyle=\scriptsize]
> ./evaluator_name simulated_file experimental_file results_file
\end{lstlisting}

\end{itemize}

\subsection{Graphical user interface application}

A more user friendly application with an interactive graphical user interface is
named as \emph{MPCOTool}. This application plots a window as the represented
in the figure~\ref{FigWindow}. The main window enable us to fit all algorithms,
parameters, data and executable files required in the simulation.
\FIG{mpcotool-en.eps}{Main window of the interactive graphical user interface
application}{FigWindow}

\section{Optimization analytical tests}

Several common tests are presented below (as can be seen in Wikipedia
\url{https://en.wikipedia.org/wiki/Test_functions_for_optimization})
in order to test the performance of the different optimization 
algorithms. In all cases, the optimization of two parameters which minimizes
an analytical function is attempted, having each problem an 
analytical solution as well. The tests were obtained from \citet{SurjanovicBingam15},
where they are classified as follows:
\begin{itemize}
\item Bowl-shaped function: Sphere function.
\item Many local minima function: Ackley's function.
\item Plate-shaped function: Booth's function.
\item Valley-shaped function: Rosenbrock's function.
\item Step ridges/drops function: Easom's function.
\item Other type function: Beale's function.
\end{itemize}
Table~\ref{TabOriginalTests} displays the absolute minimum and the domain used
for the optimization of the aforementioned functions.
\TABLE{\scriptsize}{ccc}
{
	Objective function & Minimum & Domain \\
	\hline
	\multirow{2}{*}{$f_{Sphere}(x,\,y)=x^2+y^2$} &
	\multirow{2}{*}{$f_{Sphere}(0,\,0)=0$} &
	$x\in[-5,5]$ \\ & & $y\in[-5,5]$ \\
	$f_{Ackley}(x,\,y)=20\,\C{1-\exp\PA{-\frac15\,\sqrt{\frac{x^2+y^2}{2}}}}$
	& \multirow{2}{*}{$f_{Ackley}(0,\,0)=0$} &
	$x\in[-40,40]$ \\
	$+e-\exp\C{\frac{\cos(2\,\pi\,x)+\cos(2\,\pi\,y)}{2}}$ &
	& $y\in[-40,40]$ \\
	\multirow{2}{*}{$f_{Booth}(x,\,y)=(x+2\,y-7)^2+(2\,x+y-5)^2$} &
	\multirow{2}{*}{$f_{Booth}(1,\,3)=0$} &
	$x\in[-10,10]$ \\ & & $y\in[-10,10]$ \\
	\multirow{2}{*}{$f_{Rosenbrock}(x,\,y)=100\,\PA{y-x^2}^2+(x-1)^2$} &
	\multirow{2}{*}{$f_{Rosenbrock}(1,\,1)=0$} &
	$x\in[-5,10]$ \\ & & $y\in[-5,10]$ \\
	$f_{Easom}(x,\,y)=-\cos(x)\,\cos(y)$ &
	\multirow{2}{*}{$f_{Easom}(\pi,\,\pi)=-1$} &
	$x\in[-100,100]$ \\
	$\exp\LL{-\C{(x-\pi)^2+(y-\pi)^2}}$ &
	& $y\in[-100,100]$ \\
	$f_{Beale}(x,\,y)=(1.5-x+x\,y)^2$ &
	\multirow{2}{*}{$f_{Beale}\PA{3,\,\frac12}=0$} &
	$x\in[-5,5]$ \\
	$+\PA{2.25-x+x\,y^2}^2+\PA{2.625-x+x\,y^3}^2$ &
	& $y\in[-5,5]$
}{}{TabOriginalTests}

The algorithms based on the sweep method, as the space between the variables
is traversed at regular intervals, are likely to exactly fall in the minimum
of the function when the parameters to be minimized are integer or rational
numbers. In those cases, the function has been modified in order always to get 
the minimum with irrational parameters.
\TABLE{\scriptsize}{ccc}
{
	Objective function & Minimum & Domain \\
	\hline
	\multirow{2}{*}{$g_{Sphere}(x,\,y)
		=f_{Sphere}\PA{x-\frac{\pi}{4},\,y-\frac{\pi}{4}}$} &
		\multirow{2}{*}{$g_{Sphere}\PA{\frac{\pi}{4},\,\frac{\pi}{4}}=0$} &
	$x\in[-5,5]$ \\ & & $y\in[-5,5]$ \\
	\multirow{2}{*}{$g_{Ackley}(x,\,y)
		=f_{Ackley}\PA{x-\frac{\pi}{4},\,y-\frac{\pi}{4}}$} &
	\multirow{2}{*}{$g_{Ackley}\PA{\frac{\pi}{4},\,\frac{\pi}{4}}=0$} &
	$x\in[-40,40]$ \\ & & $y\in[-40,40]$ \\
	\multirow{2}{*}{$g_{Booth}(x,\,y)
		=f_{Booth}\PA{x-\frac{\pi}{4},\,y-\frac{\pi}{4}}$} &
	\multirow{2}{*}{$g_{Booth}\PA{1+\frac{\pi}{4},\,3+\frac{\pi}{4}}=0$} &
	$x\in[-10,10]$ \\ & & $y\in[-10,10]$ \\
	$g_{Rosenbrock}(x,\,y)$ &
	$g_{Rosenbrock}\PA{1+\frac{\pi}{4},\,1+\frac{\pi}{4}}$ &
	$x\in[-5,10]$ \\ 
	$=f_{Rosenbrock}\PA{x-\frac{\pi}{4},\,y-\frac{\pi}{4}}$ &
	$=0$ &
	$y\in[-5,10]$ \\
	\multirow{2}{*}{$g_{Beale}(x,\,y)
		=f_{Beale}\PA{x-\frac{\pi}{4},\,y-\frac{\pi}{4}}$} &
	\multirow{2}{*}{$g_{Beale}\PA{3+\frac{\pi}{4},\,\frac12+\frac{\pi}{4}}=0$} &
	$x\in[-5,5]$ \\ & & $y\in[-5,5]$
}{}{TabModifiedTests}

When presenting the results, the following notation is used:
\begin{description}
\item[$N_{simulated}$]: number of performed simulations. 
\item[$\tilde{x}_i$]: value of the parameter $x$ for the best of the $i$
	performed simulations.
\item[$\overline{x}$]: optimum value of the parameter $x$.
\item[$d_i=\sqrt{\PA{\tilde{x}_i-\overline{x}}^2
	+\PA{\tilde{y}_i-\overline{y}_i}^2}$]: distance between the best of the $i$
	performed simulations and the optimum value of the parameters (in the case
    of an optimization problem with two variables).
\end{description}

The value of these functions in the $x-y$ plane is shown in figure~\ref{FigTests}.
\FIGVI{Sphere.eps}{Ackley.eps}{Booth.eps}{Rosenbrock.eps}{Easom.eps}{Beale.eps}
{Map in the $x-y$ plane showing the values of the objective functions used as 
test}{FigTests}
Figure~\ref{FigTestsZoom} shows a zoomed area of some of these functions to 
highlight their peculiarities.
\PLOTII{Ackley2.eps}{Easom2.eps}{A zoom of (left) Ackley and (right) Easom
objective functions}{FigTestsZoom}

The ability of the different algorithms in order to obtain the optimum
value for all the tests, using a fixed number of total simulations of 2500 in each method,
is then presented. The abbreviations shown in table~\ref{TabMethods}, related 
to the different combinations of algorithms and configuration parameters, are used
for the sake of simplicity.
\TABLE{\scriptsize}{ccc}
{
	Abbreviations & Algorithms & Parameters \\
	\hline
	SW-1 & SW & $N_x=N_y=50$ \\
	SW+IT-1 & SW+IT & $N_x=N_y=10$, $N_i=25$, $N_b=10$, $tol=0.5$ \\
	SW+IT-2 & SW+IT & $N_x=N_y=10$, $N_i=25$, $N_b=4$, $tol=0$ \\
	SW+CD-1 & SW+GB+CD & $N_x=N_y=10$, $N_{st}=600$, $st_x=st_y=0.1$, $rel=1$ \\
	SW+CD-2 & SW+GB+CD & $N_x=N_y=40$, $N_{st}=225$, $st_x=st_y=0.01$,
		$rel=1$ \\
	SW+RA-1 & SW+GB+RA & $N_x=N_y=10$, $N_{st}=600$, $st_x=st_y=0.1$, $rel=1$,
		$N_e=2$ \\
	SW+RA-2 & SW+GB+RA & $N_x=N_y=40$, $N_{st}=225$, $st_x=st_y=0.01$,
		$rel=1$, $N_e=2$ \\
	MC-1 & MC & $N_s=2500$ \\
	MC+IT-1 & MC+IT & $N_s=100$, $N_i=25$, $N_b=10$, $tol=0.1$ \\
	MC+IT-2 & MC+IT & $N_s=100$, $N_i=25$, $N_b=4$, $tol=0$ \\
	MC+CD-1 & MC+GB+CD & $N_s=100$, $N_{st}=600$, $st_x=st_y=0.1$, $rel=1$ \\
	MC+CD-2 & MC+GB+CD & $N_s=1600$, $N_{st}=225$, $st_x=st_y=0.01$, $rel=1$ \\
	MC+CD-3 & MC+GB+CD & $N_s=100$, $N_{st}=600$, $st_x=st_y=0.01$, $rel=0$ \\
	MC+CD-4 & MC+GB+CD & $N_s=100$, $N_{st}=600$, $st_x=st_y=0.01$, $rel=1$ \\
	MC+CD-5 & MC+GB+CD & $N_s=100$, $N_{st}=600$, $st_x=st_y=0.01$, $rel=2$ \\
	MC+CD-6 & MC+GB+CD & $N_s=100$, $N_{st}=600$, $st_x=st_y=0.1$, $rel=0$ \\
	MC+CD-7 & MC+GB+CD & $N_s=100$, $N_{st}=600$, $st_x=st_y=1$, $rel=0$ \\
	MC+RA-1 & MC+GB+RA & $N_s=100$, $N_{st}=600$, $st_x=st_y=0.1$, $rel=1$,
		$N_e=2$ \\
	MC+RA-2 & MC+GB+RA & $N_x=1600$, $N_{st}=225$, $st_x=st_y=0.01$, $rel=1$,
		$N_e=2$ \\
	MC+RA-3 & MC+GB+RA & $N_s=100$, $N_{st}=600$, $st_x=st_y=0.1$, $rel=1$,
		$N_e=3$ \\
	MC+RA-4 & MC+GB+RA & $N_s=100$, $N_{st}=600$, $st_x=st_y=0.1$, $rel=1$,
		$N_e=4$ \\
	MC+RA-5 & MC+GB+RA & $N_s=100$, $N_{st}=600$, $st_x=st_y=0.1$, $rel=1$,
		$N_e=10$ \\
	GE-1 & GE & $N_p=100$, $N_g=33$, $R_m=R_r=0$, $R_a=0.75$, $N_{bits}=32$ \\
	GE-2 & GE & $N_p=100$, $N_g=33$, $R_m=R_a=0$, $R_r=0.75$, $N_{bits}=32$ \\
	GE-3 & GE & $N_p=100$, $N_g=33$, $R_m=R_r=R_a=0.25$, $N_{bits}=32$ \\
	GE-4 & GE & $N_p=100$, $N_g=33$, $R_m=0.75$, $R_r=R_a=0$, $N_{bits}=32$ \\
	GE-5 & GE & $N_p=250$, $N_g=16$, $R_m=R_r=R_a=0.2$, $N_{bits}=32$ \\
	GE-6 & GE & $N_p=250$, $N_g=31$, $R_m=R_r=R_a=0.1$, $N_{bits}=32$ \\
	GE-7 & GE & $N_p=500$, $N_g=21$, $R_m=R_r=0$, $R_a=0.2$, $N_{bits}=32$ \\
	GE-8 & GE & $N_p=500$, $N_g=21$, $R_m=R_a=0$, $R_r=0.2$, $N_{bits}=32$ \\
	GE-9 & GE & $N_p=500$, $N_g=21$, $R_m=0.2$, $R_r=R_a=0$, $N_{bits}=32$ \\
	GE-10 & GE & $N_p=625$, $N_g=11$, $R_m=R_r=R_a=0.1$, $N_{bits}=32$ \\
	GE-11 & GE & $N_p=625$, $N_g=6$, $R_m=R_r=R_a=0.2$, $N_{bits}=32$
}{Abbreviations of the methods used in the results of the tests}
{TabMethods}

Next, the behavior of the different optimization algorithms for the sphere function
is analyzed, being a symmetric, convex, without local extrema and easy to optimize
function.

Figure~\ref{FigSphereVariables} displays all the possible combinations of the
simulated variables by the different algorithms in order to illustrate how
each method operates. It can be observed the regular way of exploring the space
of variables for the sweep method in contrast to the random method for the
Monte-Carlo method. It is shown as well the progressive reduction of the search
interval for the iterative algorithm in both cases. The genetic method also 
performs a random search, but the likelihood of falling at points in the  
vicinity of the optimum increases progressively. However, the gradient based
method rapidly searches in the direction of the optimum, from the best value
provided by the associated brute force method. 
\FIGVI{sphere-variables-sw-50-50-1.eps}{sphere-variables-mc-2500-1.eps}
{sphere-variables-sw-10-10-25-10-0.5.eps}{sphere-variables-mc-100-25-10-0.1.eps}
{sphere-variables-ge-250-16-0.2-0.2-0.2-32.eps}
{sphere-variables-mc-r-100-1-600-4-0.1-1.eps}
{Combination of variables simulated by different algorithms}{FigSphereVariables}

Figure~\ref{FigSphereSWMC} shows the convergence obtained for the sweep brute force
and Monte-Carlo methods and their combination with the iterative algorithm. It can
be observed how the convergence improves with the iterative algorithm. It is important
to note that, although theoretically the convergence increases with the iterative methods, 
low values of $N_b$ and $tol$ can cause the optimum value to fall outside of the search
interval ruining the convergence, as is the case of SW+IT-2 and MC+IT-2.
\PLOTII{sphere-evolution-sw.eps}{sphere-evolution-mc.eps}
{Convergence of the optimizacion for $g_{Sphere}$ with (left) the sweep algorithm
and (right) Monte-Carlo, both combined with the iterative algorithm and different
parameters}{FigSphereSWMC}

Figure~\ref{FigSphereSWMCGR} displays the convergence obtained with the sweep
brute force and Monte-Carlo methods coupled with the gradient based method. 
It can be shown that the convergence of the gradient based method is vastly
superior, so that in this function the the greater the number of simulations with 
the brute force method, the lower the convergence. With regard to the method of
estimating the gradient, the random method is shown superior to the coordinates
descent method. 
\PLOTII{sphere-evolution-sw-cdr.eps}{sphere-evolution-mc-cdr.eps}
{Convergence of the optimizacion for $g_{Sphere}$ with (left) the sweep algorithm
and (right) Monte-Carlo, both combined with gradient based method and different
parameters}{FigSphereSWMCGR}

The influence of the different parameters on the convergence for the gradient
based method is depicted in figure~\ref{FigSphereMCCDR}.
On the top left side, the effect of the parameter $rel$ is illustrated. With a
small step size, null values of $rel$ result in lower values of the convergence.
On the top right side, the influence of the step size is shown. In general,
it is recommended to select a step size of around a few times the expected 
approximated distance between the optimum and the best point obtained by the brute
force method. Finally, in the bottom figure can be observed that a lower number of gradient
estimates ($N_e=2$) results in the fastest convergence with the random value for the
gradient based method. 
\FIGIII{sphere-evolution-mc-cd-r.eps}{sphere-evolution-mc-cd-s.eps}
{sphere-evolution-mc-r.eps}
{Convergence of the optimizacion for $g_{Sphere}$ with Monte-Carlo and gradient based
methods and different combinations of parameters}{FigSphereMCCDR}

Figure~\ref{FigSphereGE} displays the different convergences for the genetic 
algorithm with 11 different combinations of parameters. The results, although
slightly better than those of the brute force methods, are clearly inferior to
those obtained with the iterative and gradient based methods. 
\FIGIII{sphere-evolution-ge-1-4.eps}{sphere-evolution-ge-5-8.eps}
{sphere-evolution-ge-9-11.eps}{Convergence of the optimization for $g_{Sphere}$
with the genetic algorithm and different combinations of parameters}{FigSphereGE}

Finally, the results obtained by the 23 different combinations of algorithms
and parameters for the 6 test functions are displayed in table~\ref{TabTestResults}. 
The result is presented as minus the decimal logarithm of the distance obtained
to the optimum point. This value represents the number of decimal digits of 
precision achieved. Values close to 14 have been highlighted, being this value the
theoretical precision of the machine. The results for the GE can be qualified as
disappointing. Although GE gets slightly better results for a convex function
like the sphere, its improvement over brute force method is highly questionable
for all other cases. With regard to the brute force methods, the behavior of SW
is slightly superior to MC; however, this may be a random fact. Indeed, theoretically,
MC takes advantage of situations with many variables, where the influence of each 
variable over the objective function is distinct, which is not the case for
the analyzed cases. The MPCOTool iterative algorithm do lead to a significant
improvement, with a substantial progress over the brute force methods in 
virtually all cases, even though some problems with the Rosenbrock function. 
It outperforms slightly better coupled with MC, although it may also be
a random fact related to the analyzed functions. Despite the fact that the
convergence of GB for the sphere function is higher using a lower number of
simulations for the associated brute force method, reveals itself as a bad
strategy with many local minima functions. In this case, a better approach
consist of beginning with a sufficient number of simulations by the stochastic model,
in order to obtain a point in the vicinity of the optimum, and subsequently use
the GB for a fast convergence. As regards the method to estimate the gradient,
although when RA with a low number of estimates is used, the convergence is accelerated,
it does not success in finding the optimum in some cases. CD proves to be a 
method somewhat slower but is deemed more secure. 
\TABLE{\scriptsize}{c|cccccc}
{
	Method & $g_{Sphere}$ & $g_{Ackley}$ & $g_{Booth}$ & $g_{Rosenbrock}$ &
	$f_{Easom}$ & $g_{Beale}$ \\
	\hline
	SW-1 & 1.0 & 1.4 & 1.0 & 1.1 & -0.2 & 1.4 \\
	SW+IT-1 & 12.8 & 12.4 & 10.2 & 1.5 & 9.1 & 7.4 \\
	SW+CD-1 & {\bf 15.3} & -0.7 & {\bf 14.6} & 11.6 & -1.0 & {\bf 13.6} \\
	SW+CD-2 & {\bf 15.3} & {\bf 15.3} & {\bf 14.6} & 11.5 & 8.1 & {\bf 13.8} \\
	SW+RA-1 & {\bf 14.6} & -0.7 & {\bf 14.6} & 4.3 & -1.0 & 11.7 \\
	SW+RA-2 & {\bf 15.3} & {\bf 15.3} & {\bf 13.7} & 2.8 & 8.1 & 1.4 \\
	MC-1 & 1.1 & 0.4 & 1.3 & 0.7 & -0.2 & 1.0 \\
	MC+IT-1 & {\bf 14.0} & 12.8 & 11.1 & 4.0 & 9.0 & 8.3 \\
	MC+CD-1 & {\bf 15.3} & -0.6 & {\bf 14.1} & 11.9 & -0.8 & {\bf 14.1} \\
	MC+CD-2 & {\bf 15.3} & {\bf 15.1} & {\bf 14.6} & 8.6 & -0.3 & 13.4 \\
	MC+RA-1 & {\bf 15.1} & -0.6 & {\bf 14.1} & 1.7 & -0.8 & 13.1 \\
	MC+RA-2 & {\bf 15.3} & {\bf 15.3} & {\bf 14.6} & 0.6 & -0.3 & 8.0 \\
	GE-1 & 0.8 & 0.6 & 1.0 & 0.2 & -0.3 & 0.7 \\
	GE-2 & 2.2 & 0.8 & 1.0 & 1.1 & -0.4 & 1.1 \\
	GE-3 & 0.8 & 0.8 & 0.6 & 0.2 & -0.3 & 1.4 \\
	GE-4 & 2.2 & 0.8 & 1.9 & 0.6 & -0.2 & 1.4 \\
	GE-5 & 3.1 & 2.2 & 0.8 & 0.3 & 0.7 & 1.3 \\
	GE-6 & 2.5 & 0.1 & 1.4 & 1.1 & 1.3 & 1.3 \\
	GE-7 & 1.6 & 0.0 & 1.4 & 0.9 & -0.3 & 0.6 \\
	GE-8 & 2.2 & 0.7 & 1.4 & 1.3 & 0.0 & 1.3 \\
	GE-9 & 1.8 & 0.7 & 1.3 & 1.1 & -0.2 & 0.9 \\
	GE-10 & 2.3 & 0.5 & 0.9 & 0.7 & -0.4 & 0.9 \\
	GE-11 & 1.7 & 0.4 & 1.7 & 0.8 & 0.2 & 1.2
}{Error de los métodos, estimado como $-\log_{10}\PA{d_{2500}}$, en los tests.
En negrita se han remarcado los que han alcanzado la precisión de la máquina
(aproximadamente 14 dígitos en doble precisión)}{TabTestResults}

\section{Practical applications}

In what follows, a few cases of practical application of MPCOTool in combination with
different simulation codes are presented. They deal with the optimization
or calibration 
of variables in models used for open channel flow, surface irrigation, sprinkler irrigation and irrigation
engines movement. All input data files can be downloaded from the web page \citep{MPCOToolGit}.

Most of the cases have been run on a laptop computer equipped with an Intel(R) Core(TM) i7 M620 2.67GHz processor. 
Then, the computation has been performed in four parallelized tasks to make the most of the processor's double nucleus with hyperthreading.
Only the optimization of the management of the Canal de Violada, much more computationally expensive, has been performed in the BIFI cluster Memento.

\subsection{Optimization of a canal management}

A real irrigation canal has been analyzed in order to find out the optimal
values of two variables of interest which take into account the daily gate
opening modification time. The area of study is located in the North-east of
Spain, in the province of Huesca. It consists of the first 13657 meters of the
Canal de Violada. The studied stretch was designed for a maximum discharge of
6~m$^3$/s. This stretch delivers water to three irrigation communities:
Almudévar, Gurrea and El Temple. In figure~\ref{FigViolada} a diagram with the
gates and spillways locations is shown.
\psset{xunit=9mm,yunit=6mm}
\PSPICTURE{-1}{-2}{11.4}{2}
{
	\scriptsize
	\rput(-0.5,0){Inlet}
	\rput(10.7,0){Outlet}
	\psline(0,0)(10,0)
	\psline{->}(7.5,0)(7.5,-1)
	\rput(7.5,-1.4){Spillway}
	\psline{->}(10,0)(10,-1)
	\rput(10,-1.4){Spillway}
	\psline{->}(3,0)(3,1)
	\rput(3,1.4){Almudévar}
	\psline{->}(8.5,0)(7.5,1)
	\rput(7.5,1.4){Gurrea}
	\psline{->}(9,0)(10,1)
	\rput(10,1.4){El Temple}
	\psline{<->}(0,-0.3)(3,-0.3)
	\rput(1.5,-0.7){5007 m}
	\psline{<->}(3,-0.3)(7.5,-0.3)
	\rput(5.25,-0.7){8346 m}
	\psline{<->}(7.5,-0.3)(8.5,-0.3)
	\rput(8,-0.7){270 m}
	\psline{<->}(8.5,-0.3)(9,-0.3)
	\rput(8.75,-0.7){7 m}
	\psline{<->}(9,-0.3)(10,-0.3)
	\rput(9.5,-0.7){27 m}
}{Sketch showing the position of the two spillways and the three gates on the
Canal de Violada. The dimensions are not on scale for a better visualization}
{FigViolada}

The required discharge at every gate for a modernization scenario to sprinkler irrigation was obtained after an elaborate 
field analysis. Taking into account the crop distribution, soil water retention properties, the electricity cost depending on the hour of the day and the design of a 
reservoir in the area, seven different scenarios were obtained as a function of the historical irrigation requirements for 
the same period using real data \citet{Zapata09}. A 14 days period was selected from
one of these scenarios in order to optimize the channel management.

Two cross sections can be distinguished in the channel, the longer 13353 meters initial reach
and the last 304 meters. Both share the same bottom slope, $S_0$ = 0.00059 but
they differ in the cross section dimensions, as shown in
Figure~\ref{FigCrossSections}, and in the value of the Gauckler-Manning
roughness coefficient (0.014 and 0.02~s~m$^{-1/3}$ for the first
and the final reaches respectively). The values correspond to polished and
coarse concrete \citep{Chow59}.
\psset{xunit=9mm,yunit=9mm}
\PSPICTURE{0}{-0.6}{12.7}{2.450}
{
	\psline(0,2.050)(0.615,0)(3.259,0)(3.874,2.050)
	\psline{<->}(0.615,-0.2)(3.259,-0.2)
	\rput(1.937,-0.4){2.644 m}
	\psline{<->}(0,2.250)(3.874,2.250)
	\rput(1.937,2.450){3.874 m}
	\psline{<->}(4.074,0)(4.074,2.050)
	\rput(4.774,1.025){2.050 m}
	\psline(5.5,1.8)(5.5,1.5)(7,0)(9.5,0)(11,1.5)(11,1.8)
	\psline{<->}(5.5,2)(11,2)
	\rput(8.25,2.2){5.500 m}
	\psline{<->}(7,-0.2)(9.5,-0.2)
	\rput(8.25,-0.4){2.500 m}
	\psline{<->}(11.2,0)(11.2,1.5)
	\rput(11.9,0.75){1.500 m}
	\psline{<->}(11.2,1.5)(11.2,1.8)
	\rput(11.95,1.65){0.300 m}
}{Channel cross sections for the first stretch of 13353 m (left) and the last part of 304 m (right)}{FigCrossSections}

Two key optimization variables have been studied: $\Delta t_A$ and
$\Delta t_{GT}$. Where $\Delta t_A$ takes into account the delay between the
modification time of the inlet discharge and the modification time in the
Almudévar gate and $\Delta t_{GT}$ takes into account the delay between the
inlet and Gurrea and Temple gates modification. Before the development of this 
study, the channel guards responsible for its management carried out the gates
opening using fixed values $\Delta t_A=$1h and $\Delta t_{GT}=$3h30m.

The initial conditions for the canal were a steady state with a discharge of
2~m$^3$/s. The objective of this work was to provide
the required daily discharge to the three important irrigation gates as well as
to keep a constant discharge of 2 m$^3$/s at the outlet gate. It is important to 
stress that Gurrea and Temple gates are only separated by a few meters and are located
near the outlet gate.

SWIGS open source software \citep{Swigs} has been used to simulate the channel
flow. Each optimization executed a total number of 1024 simulations and took 
approximately 14 hours using 64 cores in the Memento cluster housed at BIFI.

Table~\ref{TabSwigs} displays the results obtained for the optimal coefficient
values and the corresponding value of the evaluation function, where the error
norm is defined as the root mean square error between demanded discharges and
supplied discharges multiplied by a factor of 10 in cases of channel overflow.
The results are similar when comparing the different optimization methods.
Nevertheless, it can be observed that the iterative algorithm, applied to the 
brute force methods, improves slightly the results for this canal management.
It is also remarkable that the genetic algorithm obtains the best
and the worst of the results, hence indicating that this method
is sensitive to the election of the genetic parameters. With the channel
guards management pattern this error norm is much higher, due not only to a greater error
in the desired outlet discharge but also to a slight overflow in one of the 
spillways of the canal.

\TABLE{\scriptsize}{cccc}
{
	Optimization & Optimization & Optimal empirical & Objective function
	\\ algorithm & parameters & parameters & value
	\\ \hline
	\multicolumn{2}{c}{Manual management} & $\Delta t_A=3600$ s & 1.049056
	\\ & & $\Delta t_{GT}=12600$ s
	\\ \hline
	Sweeps & $N_s=1024$ & $\Delta t_A=3368$ s & 0.047170
	\\ & $N_i=1$ & $\Delta t_{GT}=3716$ s
	\\ \hline
	Sweeps & $N_s=256$ & $\Delta t_A=3329$ s & 0.047148
	\\ & $N_i=4$ & $\Delta t_{GT}=3742$ s
	\\ & $N_b=20$ &
	\\ & $tol=0.1$
	\\ \hline
	Monte-Carlo & $N_s=1024$ & $\Delta t_A=3193$ s & 0.047183
	\\ & $N_i=1$ & $\Delta t_{GT}=3705$ s
	\\ \hline
	Monte-Carlo & $N_s=256$ & $\Delta t_A=3250$ s & 0.047139
	\\ & $N_i=4$ & $\Delta t_{GT}=3751$ s
	\\ & $N_b=4$
	\\ & $tol=0.1$
	\\ \hline
	Genetic & $N_p=256$ & $\Delta t_A=3363$ s & 0.047135
	\\ & $N_g=9$ & $\Delta t_{GT}=3752$ s
	\\ & $R_m=0.125$
	\\ & $R_r=0.125$
	\\ & $R_a=0.125$
	\\ \hline
	Genetic & $N_p=64$ & $\Delta t_A=3375$ s & 0.047252
	\\ & $N_g=21$ & $\Delta t_{GT}=3599$ s
	\\ & $R_m=0.25$
	\\ & $R_r=0.25$
	\\ & $R_a=0.25$
	\\ \hline
}{Optimal empirical parameters and value of the evaluation function in the simulation of the Canal de Violada using program SWIGS and several optimization algorithms in MPCOTool with the same total number of simulations ($N_{total}=1024$)}
{TabSwigs}

Figure~\ref{FigSwigs} shows the supplied discharges at the inlet and at the different
gates using the default schedule developed by the channel guards and that 
obtained in the best of our simulations. It can be observed that in both cases 
the desired discharge at the different gates in Almudévar, Gurrea and El Temple is supplied,
with some transient peaks affecting the outlet discharge.
This work confirms that an optimized management reduces remarkably the amplitude and the duration of these undesired peaks.

\FIGII{Violada-contributions.eps}{Violada-optimized-contributions.eps}
{Temporal evolution of discharges supplied at inlet, outlet and gates as (top)
using the opening times applied by the canal guards and (bottom) the optimum
opening times obtained in this work}{FigSwigs}

\subsection{Calibration of empirical parameters on surface irrigation}

MPCOTool has also been used to find out the empirical parameters required by the friction and infiltration
models used in the open source software SURCOS \citep{Surcos,SurcosGit,JaviSurcos3} for the simulation of the four furrow fertigation experiments published in \citet{JaviSurcos2}. The furrows were $100$ m long and they were simulated using 100 computational cells per furrow. The furrows were close together, they had the same geometry and the experiments were almost simultaneous, hence the soil properties were assumed uniform. 

The friction model used in SURCOS is the Gauckler-Manning model. The infiltration model is the Kostiakov-Lewis model. They require calibration of three coefficients: the Gauckler-Manning number $n$ and the infiltration parameters $K$ and $a$. In the original paper, a brute force method using 3000 simulations was applied, each of them including the four experiments. In the present work, the same number of simulations has been used with the calibration methods implemented in MPCOTool. The execution of 3000 simulations in the laptop computer took about 1h20m.  

Table~\ref{TabSurcos} displays the results obtained for the optimal coefficient values and the corresponding
value of the evaluation function, where the error norm is the same as in \citet{JaviSurcos2}. The results are similar among the different methods and also similar to those in the original paper. This is due to the existence of a relatively large region of combinations of the empirical parameters producing similar values in the evaluation function, thus preventing from an accurate convergence to the optimum set. However, it can be noticed that both the iterative method and the genetic methods produce better results than the Monte-Carlo method without iterations with the same total number of simulations.

\TABLE{\scriptsize}{cccc}
{
	Optimization & Optimization & Optimal empirical & Objective function
	\\ algorithm & parameters & parameters & value
	\\ \hline
	Monte-Carlo & $N_s=3000$ & $n=0.0395$ & 0.3430
	\\ & $N_i=1$ & $K=7.861\cdot 10^{-4}$
	\\ & & $a=0.534$
	\\ \hline
	Monte-Carlo & $N_s=500$ & $n=0.0422$ & 0.3321
	\\ & $N_i=6$ & $K=9.994\cdot 10^{-4}$
	\\ & $N_b=10$ & $a=0.497$
	\\ & $tol=0.2$
	\\ \hline
	Genetic & $N_p=750$ & $n=0.0399$ & 0.3339
	\\ & $N_g=6$ & $K=9.907\cdot 10^{-4}$
	\\ & $R_m=0.2$ & $a=0.498$
	\\ & $R_r=0.2$
	\\ & $R_a=0.2$
	\\ \hline
	Genetic & $N_p=300$ & $n=0.0417$ & 0.3322
	\\ & $N_g=31$ & $K=9.989\cdot 10^{-4}$
	\\ & $R_m=0.1$ & $a=0.496$
	\\ & $R_r=0.1$
	\\ & $R_a=0.1$
	\\ \hline
}{Optimal empirical parameters and value of the evaluation function in the simulation of the furrow irrigation cases in \citet{JaviSurcos2} using program SURCOS and several optimization algorithms in MPCOTool with the same total number of simulations ($N_{total}=3000$)}{TabSurcos}

Figure~\ref{FigSurcos} shows the results of the water depths and solute concentration from the simulation using the coefficients obtained by the Monte-Carlo method with $N_i=6$, compared with the experimental values.

\FIGVI{surcos-advance.eps}{surcos-depth.eps}{surcos-solute-q1.eps}
{surcos-solute-q2.eps}{surcos-solute-q3.eps}{surcos-solute-q4.eps}
{(top left) Advance time profile, (top right) inlet depth evolution and
(middle-bottom) solute concentration evolution at probes for the experiments
Q1-Q4 described in \citet{JaviSurcos2} simulated with the optimal calibrated
parameters obtained for the Monte-Carlo method with $N_i=6$ (see
table~\ref{TabSurcos})}{FigSurcos}

\subsection{Calibration of empirical parameters of the ballistic model on
sprinkler irrigation}

The ballistic model \citep{Fukui80,Playan06} is the most widespread to characterize the behaviour and performance of sprinklers in sprinkler irrigation management. The model assumes that the travelling drops are approximately spherical and subject to the resulting effect of gravity and drag forces. The ejecting drop velocity is required by the model, and it is frequent to assume that the jet is compact enough to consider that all the drops carry the same velocity when leaving the sprinkler. This velocity can be estimated either by measuring the pressure and using Bernoulli's equation or, alternatively, by measuring the discharge and dividing by the outlet cross section. Other data required to characterize the water spread are related to the drop size distribution. The model used in the present work, described in \cite{Ouazaa14}, is based on three parameters $D_{50}$, $n$ and $P$. Furthermore, to include the influence of the wind, the model involves two more aerodynamic resistance coefficients:
$k_1$ y $k_2$.
The model is calibrated in two steps. First, the coefficients $D_{50}$, $n$ and $P$ are fitted to adjust the water distribution in windless conditions and are considered representative of the sprinkler model at a given pressure. In a second step, the coefficients $k_1$ and $k_2$ fitting better the water distribution in wind conditions are found.

In the present example, a spray sprinkler Senninger N44 at a working pressure of 138 kPa will be calibrated. In this sprinkler model, the water jet impacts against a fixed plate. In order to estimate the water velocity after the impact, an image technique as described in \citet{Salvador09} was applied. According to this measurements, the head loss due to the impact against the plate was found to be of 50\%.

Table~\ref{TabSprinklerI} shows the results from the calibration of parameters $D_{50}$, $n$ and $P$ in windless conditions using a total number of 1000 simulations with different optimization algorithms. The computation time was around 7 minutes in the laptop computer. The results show that the best results are supplied by the iterative Monte-Carlo method followed by the genetic algorithms. In this case, the sweep method leads to worse results, mainly when supplied with the iterative method. 

\TABLE{\scriptsize}{cccc}
{
	Optimization & Optimization & Optimal empirical & Objective function
	\\ algorithm & parameters & parameters & value
	\\ \hline
	Sweeps & $N_s=1000$ & $D_{50}=3.78$ mm & 2.54 mm
	\\ & $N_i=1$ & $n=17.778$
	\\ & & $P=0.556$
	\\ \hline
	Sweeps & $N_s=125$ & $D_{50}=3.50$ mm & 3.24 mm
	\\ & $N_i=8$ & $n=10.225$
	\\ & $N_b=8$ & $P=0.364$
	\\ & $tol=0.4$
	\\ \hline
	Monte-Carlo & $N_s=1000$ & $D_{50}=3.07$ mm & 2.01 mm
	\\ & $N_i=1$ & $n=21.513$
	\\ & & $P=0.770$
	\\ \hline
	Monte-Carlo & $N_s=125$ & $D_{50}=3.06$ mm & 1.60 mm
	\\ & $N_i=8$ & $n=20.878$
	\\ & $N_b=8$ & $P=0.388$
	\\ & $tol=0.4$
	\\ \hline
	Genetic & $N_p=250$ & $D_{50}=3.06$ mm & 1.71 mm
	\\ & $N_g=6$ & $n=21.001$
	\\ & $R_m=0.2$ & $P=0.563$
	\\ & $R_r=0.2$
	\\ & $R_a=0.2$
	\\ \hline
	Genetic & $N_p=100$ & $D_{50}=3.06$ mm & 1.62 mm
	\\ & $N_g=31$ & $n=19.963$
	\\ & $R_m=0.1$ & $P=0.377$
	\\ & $R_r=0.1$
	\\ & $R_a=0.1$
	\\ \hline
}{Optimal empirical parameters and value of the evaluation function in the case of the sprinkler irrigation
using different optimization algorithms in MPCOTool with the same number of total simulations ($N_{total}=1000$)}{TabSprinklerI}

Next, using the optimal $D_{50}=3.06$ mm, $n=20.878$ and $P=0.388$ obtained by the Monte-Carlo method (Monte-Carlo with 8 iterations, see table~\ref{TabSprinklerI}) the values of $k_1$ and $k_2$ were calibrated in an experiment with medium wind velocity of 2.84 m/s. The different algorithms in MPCOTool were used with a total number of 400 simulations in all cases. Their computational time was around 4 minutes in the laptop computer. In this case, the genetic algorithms provided the best results  (note that they provided identical results in two different configurations), although the rest of the methods reached similar values.

\TABLE{\scriptsize}{cccc}
{
	Optimization & Optimization & Optimal empirical & Objective function
	\\ algorithm & parameters & parameters & value
	\\ \hline
	Sweeps & $N_s=400$ & $k_1=0.263$ & 12.17 mm
	\\ & $N_i=1$ & $k_2=0.105$
	\\ \hline
	Sweeps & $N_s=100$ & $k_1=0.284$ & 12.17 mm
	\\ & $N_i=4$ & $k_2=0.098$
	\\ & $N_b=11$
	\\ & $tol=0.2$
	\\ \hline
	Monte-Carlo & $N_s=400$ & $k_1=0.396$ & 12.19 mm
	\\ & $N_i=1$ & $k_2=0.067$
	\\ \hline
	Monte-Carlo & $N_s=100$ & $k_1=0.370$ & 12.15 mm
	\\ & $N_i=4$ & $k_2=0.079$
	\\ & $N_b=4$
	\\ & $tol=0.2$
	\\ \hline
	Genetic & $N_p=100$ & $k_1=0.400$ & 12.09 mm
	\\ & $N_g=6$ & $k_2=0.070$
	\\ & $R_m=0.2$
	\\ & $R_r=0.2$
	\\ & $R_a=0.2$
	\\ \hline
	Genetic & $N_p=100$ & $k_1=0.400$ & 12.09 mm
	\\ & $N_g=11$ & $k_2=0.070$
	\\ & $R_m=0.1$
	\\ & $R_r=0.1$
	\\ & $R_a=0.1$
	\\ \hline
}{Optimal parameters and values of the evaluations function in the experiment of the sprinkler irrigation under wind conditions of 2.84 m/s using different optimization algorithms implemented in MPCOTool with the same total number of simulations ($N_{total}=400$)}{TabSprinklerII}

Finally, figure~\ref{FigSprinkler} shows the measured (in pluviometers) and simulated water distribution using the optimal parameters in windless and wind conditions of average velocity 2.84 m/s.

\FIGII{sprinkler-0.eps}{sprinkler-2,84.eps}
{(top) Radial pluviometry for non-wind conditions and (bottom) pluviometry at
the two pluviometers axes with wind average velocity 2.84 m/s}{FigSprinkler}

\subsection{Calibration of empirical parameters of the movement of a
sprinkler center-pivot}

The movement of a center-pivot tower follows a chaotic pattern depending on the movement of the exterior tower, the tower start and stop angles and the start and stop velocities. In \citet{Ouazaa15} a model was proposed to simulate the tower movements and several controlled experiments  were carried out to measure them in a real field center-pivot. The exterior tower controls the movement, with a sequence of working periods that depend on the cycle period and the working percentage, both adjustable to reach a desired irrigation service. The rest of the towers move according to a complex pattern (see figure~\ref{FigPivotDiagram}). 

\psset{unit=1mm}
\PSPICTURE{-10}{-6}{93}{20}
{
	\rput(25,17){$\alpha_i<\alpha_{start}\;\Rightarrow\;T_i$ start}
	\rput(65,17){$\alpha_i>\alpha_{stop}\;\Rightarrow\;T_i$ stop}
	\psarc{->}(0,0){93}{0}{7}
	\psline(0,0)(20,0)(40,1)(60,2.5)(90,5.5)
	\pscircle*(20,0){0.5}
	\pscircle*(40,1){0.5}
	\pscircle*(60,2.5){0.5}
	\pscircle*(80,4.5){0.5}
	\pscircle*(0,0){1.0}
	\rput(0,-3){Centre}
	\rput(20,-3){$T_1$}
	\rput(40,-2){$T_2$}
	\rput(60,-0.5){$T_3$}
	\rput(80,1.5){$T_4$}
	\psarc(20,0){3}{2.86}{180}
	\psarc(40,1){3}{4.29}{177.14}
	\psarc(60,2.5){3}{5.71}{175.71}
	\rput(20,6){$\alpha_1$}
	\rput(40,7){$\alpha_2$}
	\rput(60,8.5){$\alpha_3$}
}{Example of movement of a centre-pivot irrigation engine with
four towers}{FigPivotDiagram}

The model includes four empirical parameters to calibrate: the average angles of start $\overline{\alpha_{start}}$ and stop $\overline{\alpha_{stop}}$, the uncertainty in these angles $\delta$ and the start and stop times $\tau$. In every tower cycle, the start and stop angles are obtained as:
\EQ
{
	\alpha_{start}=\overline{\alpha_{start}}+(r-0.5)\,\delta,\quad
	\alpha_{stop}=\overline{\alpha_{stop}}+(r-0.5)\,\delta,
}{EqPivotStartStop}
with $r$ a random number defined with uniform probability in the range $r\in[0,1)$. The same time $\tau$ is considered for start and stop, and the velocity
increases or decreases linearly (see figure~\ref{FigPivotVelocity}).

\psset{unit=1mm}
\PSPICTURE{-16}{-6}{75}{39}
{
	\scriptsize
	\psline{->}(0,0)(0,30)
	\psline{->}(0,0)(70,0)
	\rput(0,36){Tower}
	\rput(0,32){linear velocity}
	\rput(70,-3){Time}
	\psline(0,0)(10,0)(15,20)(25,20)(30,0)(45,0)(50,20)(60,20)(65,0)
	\rput(-8,22){Maximum}
	\rput(-8,18){velocity}
	\psline[linestyle=dotted](0,20)(15,20)
	\psline{<->}(10,23)(15,23)
	\rput(12.5,26){$\tau$}
	\psline{<->}(10,29)(30,29)
	\rput(20,35){Start}
	\rput(20,32){time}
	\psline{<->}(25,23)(30,23)
	\rput(27.5,26){$\tau$}
	\psline{<->}(30,23)(45,23)
	\rput(37.5,29){Stop}
	\rput(37.5,26){time}
}{Linear velocity of a centre-pivot tower on starts and stops}{FigPivotVelocity}

The movement of a real pivot with four towers separated 50.11 m is next simulated and calibrated. The maximum linear velocity of each tower were measured to be: $v_1=0.02738$ m/s, $v_2=0.02824$ m/s, $v_3=0.03008$ m/s and $v_4=0.03753$ m/s.
The exterior tower is considerably faster as it carries less weight and produces less friction.
The start and stop times of each tower were measured in four experiments of 24 hours with the pivot working in cycles of 71s at 100\%, 52\%, 42\% y 27.48\%.

The times were grouped in four histograms and the evaluation function was defined as the mean square error between the measured and simulated histograms.
Table~\ref{TabPivot} shows some of the results obtained in a total of 10000 simulations of each of the four experiments, taking around 50 minutes each in the same laptop computer used before.

The best results where obtained with the genetic algorithms. Note that in this case again the genetic algorithm produces the results with the lowest $R$ coefficient values. It is also worth noting that the iterative algorithm improves the results when applied to the Monte Carlo method but it makes things slightly worse in the sweep method.

\TABLE{\scriptsize}{cccc}
{
	Optimization & Optimization & Optimal empirical & Objective function
	\\ algorithm & parameters & parameters & value
	\\ \hline
	Sweep & $N_s=10000$ & $\overline{\alpha_{start}}=179.910^\circ$
	& 9924.1
	\\ & $N_i=1$ & $\overline{\alpha_{stop}}=180.300^\circ$
	\\ & & $\delta=0.130^\circ$
	\\ & & $\tau=4.40$s
	\\ \hline
	Sweep & $N_s=625$ & $\overline{\alpha_{start}}=179.335^\circ$
	& 10443.4
	\\ & $N_i=16$ & $\overline{\alpha_{stop}}=179.735^\circ$
	\\ & $N_b=10$ & $\delta=0.113^\circ$
	\\ & $tol=0.4$ & $\tau=4.08$s
	\\ \hline
	Monte-Carlo & $N_s=10000$
	& $\overline{\alpha_{start}}=179.768^\circ$ & 12899.4
	\\ & $N_i=1$ & $\overline{\alpha_{stop}}=180.177^\circ$
	\\ & & $\delta=0.139^\circ$
	\\ & & $\tau=3.77$s
	\\ \hline
	Monte-Carlo & $N_s=625$
	& $\overline{\alpha_{start}}=179.786^\circ$ & 9741.8
	\\ & $N_i=16$ & $\overline{\alpha_{stop}}=180.194^\circ$
	\\ & $N_b=10$ & $\delta=0.122^\circ$
	\\ & $tol=0.1$ & $\tau=3.82$s
	\\ \hline
	Genetic & $N_p=1000$ & $\overline{\alpha_{start}}=179.800^\circ$
	& 9552.8
	\\ & $N_g=16$ & $\overline{\alpha_{stop}}=180.190^\circ$
	\\ & $R_m=0.2$ & $\delta=0.137^\circ$
	\\ & $R_r=0.2$ & $\tau=4.39$s
	\\ & $R_a=0.2$
	\\ \hline
	Genetic & $N_p=400$ & $\overline{\alpha_{start}}=179.751^\circ$
	& 9187.5
	\\ & $N_g=81$ & $\overline{\alpha_{stop}}=180.166^\circ$
	\\ & $R_m=0.1$ & $\delta=0.136^\circ$
	\\ & $R_r=0.1$ & $\tau=3.32$s
	\\ & $R_a=0.1$
	\\ \hline
}{Optimal parameters and values of the evaluation function in the four towers pivot case in \citet{Ouazaa15} using different optimization algorithms implemented in MPCOTool with the same number of total simulations ($N_{total}=10000$)}{TabPivot}

In figures \ref{FigPivot100} to \ref{FigPivot27} the histograms of the number
of measured and simulated starts and stops are represented for the different
machine workings.
Note that the figures are not represented with uniform scales to better
visualization of the differences among measured and simulated results.
The agreement between measured and simulated data when using the parameters calibrated with the optimal genetic algorithm must be considered reasonable taking into account the chaotic character of the movement.
However, coupling a sprinkler irrigation model, it could be concluded that losses in water distribution uniformity associated to the tower movement variability can be considered negligible \citep{Ouazaa15}.

\FIGIV{pivot-measured-starts-100.eps}{pivot-measured-stops-100.eps}
{pivot-simulated-starts-100.eps}{pivot-simulated-stops-100.eps}
{Histogram of the number of (top left) measured starts, (top right) measured stops, (bottom left)
simulated starts and (bottom right) simulated stops for the pivot towers working at 100\%
velocity}{FigPivot100}

\FIGIV{pivot-measured-starts-52.eps}{pivot-measured-stops-52.eps}
{pivot-simulated-starts-52.eps}{pivot-simulated-stops-52.eps}
{Histogram of the number of (top left) measured starts, (top right) measured stops, (bottom left)
simulated starts and (bottom right) simulated stops for the pivot towers working at 52\%
velocity}{FigPivot52}

\FIGIV{pivot-measured-starts-42.eps}{pivot-measured-stops-42.eps}
{pivot-simulated-starts-42.eps}{pivot-simulated-stops-42.eps}
{Histogram of the number of (top left) measured starts, (top right) measured stops, (bottom left)
simulated starts and (bottom right) simulated stops for the pivot towers working at 42\%
velocity}{FigPivot42}

\FIGIV{pivot-measured-starts-27,48.eps}{pivot-measured-stops-27,48.eps}
{pivot-simulated-starts-27,48.eps}{pivot-simulated-stops-27,48.eps}
{Histogram of the number of (top left) measured starts, (top right) measured stops, (bottom left)
simulated starts and (bottom right)simulated stops for the pivot towers working at 27.48\% velocity}{FigPivot27}

\section{Conclusions}

The features and design of MPCOTool, a new open source software tool to enable efficient calibration and optimization of empirical coefficients present in simulation models, has been presented. The program includes the option of two classic brute force models, the sweep and the Monte-Carlo method, both supplied with the option of an iterative procedure to improve convergence. Also, MPCOTool offers the alternative of a genetic algorithm as implemented in Genetic.

The new tool allows an efficient performance, making the most of the processors present in a single computer and allowing an easy extension to parallelization distributed among different computers. In whole, a considerable data capacity and computational speed are achieved with independence of the physical problem under study or the algorithm chosen.

For the analyzed cases, all the implemented optimization algorithms have reached similar results with the same total number of simulations. However, the iterative algorithm applied in combination with the Monte-Carlo method and the genetic algorithm leads to slightly better results than the pure brute force techniques. On the other hand, the iterative algorithm does not improve significantly the sweep method results. It is important to stress that the genetic algorithm provides always the best results with the lowest values of the ratio coefficients. This indicates that the efficiency of the genetic algorithm depends on the values of that coefficients and requires further research. 

MPCOTool has proved to be flexible in the adaptation to the syntax of diverse simulation codes and useful in the calibration and optimization of parameters involved in rather different irrigation problems. In the present work it has been shown successful for practical applications such as open channel flow management, furrow fertigation, sprinkler irrigation and sprinkler tower movement design.

\section*{Acknowledgements}

The authors would like to thank Arturo Giner and Guillermo Losilla for their support and the BIFI
Institute for letting us the use of the Memento cluster.
This research was funded by the MCINN of the Government of Spain through grants AGL2010-21681-C03-01 and BIA2011-30192-C02-01, and the FPI-MINECO PhD grants program.

\section*{References}
\bibliography{bib}

\end{document}
